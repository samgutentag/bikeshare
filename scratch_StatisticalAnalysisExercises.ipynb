{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from glob import glob\n",
    "\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# station ID numbers that are in San Francisco\n",
    "sf_stations = [ 39,41,42,45,46,47,48,49,50,51,54,55,56,57,58,59,60,61,62,63,\n",
    "                64,65,66,67,68,69,70,71,72,73,74,75,76,77,82,90,91]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Trip Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('Loading Trip Data...')\n",
    "\n",
    "try:\n",
    "    file_path_slug = '../../datasets/bayareabikeshare/*_trip_data.csv'\n",
    "    \n",
    "    # glob all files\n",
    "    file_list = glob(file_path_slug)\n",
    "    \n",
    "    trip = pd.DataFrame()\n",
    "    \n",
    "    counter = 1\n",
    "    chunks = []\n",
    "    \n",
    "    # load data from each file\n",
    "    for file in file_list:\n",
    "        \n",
    "        # import file in chunks\n",
    "        for chunk in pd.read_csv(file, chunksize=10000, iterator=True):\n",
    "            \n",
    "            chunk = chunk.set_index('Trip ID')\n",
    "            \n",
    "            chunk.columns = ['Duration', 'Start Date', 'Start Station', 'Start Terminal', 'End Date', \n",
    "                             'End Station', 'End Terminal', 'Bike #', 'Subscriber Type', 'Zip Code']\n",
    "\n",
    "            chunks.append(chunk)\n",
    "            \n",
    "        print('\\tfinished file! (%d of %d)'% (counter, len(file_list)))\n",
    "        counter += 1\n",
    "    \n",
    "    # concat chunks\n",
    "    trip = pd.concat(chunks)\n",
    "    \n",
    "    print('Data Loaded Successfully!')\n",
    "except:\n",
    "    print('oops... something went wrong loading the data :(')\n",
    "    \n",
    "trip.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Weather Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('Loading Weather Data...')\n",
    "\n",
    "try:\n",
    "    file_path_slug = '../../datasets/bayareabikeshare/*_weather_data.csv'\n",
    "\n",
    "    # glob all files\n",
    "    file_list = glob(file_path_slug)\n",
    "\n",
    "    weather = pd.DataFrame()\n",
    "\n",
    "    counter = 1\n",
    "    chunks = []\n",
    "\n",
    "    # load data from each file\n",
    "    for file in file_list:\n",
    "\n",
    "        # import file in chunks\n",
    "        for chunk in pd.read_csv(file, chunksize=10000, iterator=True):\n",
    "\n",
    "            chunk.columns = ['Date', 'Max_Temperature_F', 'Mean_Temperature_F', 'Min_TemperatureF', 'Max_Dew_Point_F', \n",
    "                             'MeanDew_Point_F', 'Min_Dewpoint_F', 'Max_Humidity', 'Mean_Humidity', 'Min_Humidity', \n",
    "                             'Max_Sea_Level_Pressure_In', 'Mean_Sea_Level_Pressure_In', 'Min_Sea_Level_Pressure_In', \n",
    "                             'Max_Visibility_Miles', 'Mean_Visibility_Miles', 'Min_Visibility_Miles', \n",
    "                             'Max_Wind_Speed_MPH', 'Mean_Wind_Speed_MPH', 'Max_Gust_Speed_MPH', 'Precipitation_In', \n",
    "                             'Cloud_Cover', 'Events', 'Wind_Dir_Degrees', 'zip']\n",
    "\n",
    "            chunk = chunk.set_index('Date')\n",
    "\n",
    "            chunks.append(chunk)\n",
    "\n",
    "        print('\\tfinished file! (%d of %d)'% (counter, len(file_list)))\n",
    "        counter += 1\n",
    "\n",
    "    # concat chunks\n",
    "    weather = pd.concat(chunks)\n",
    "\n",
    "    print('Data Loaded Successfully!')\n",
    "except:\n",
    "    print('oops... something went wrong loading the data :()')\n",
    "\n",
    "weather.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Status Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('Loading Status Data...')\n",
    "\n",
    "# try:\n",
    "file_path_slug = '../../datasets/bayareabikeshare/*_status_data.csv'\n",
    "\n",
    "# glob all files\n",
    "file_list = glob(file_path_slug)\n",
    "\n",
    "status = pd.DataFrame()\n",
    "\n",
    "counter = 1\n",
    "chunks = []\n",
    "\n",
    "# load data from each file\n",
    "for file in file_list:    \n",
    "    \n",
    "    chunk = pd.read_csv(file, parse_dates=True)\n",
    "    chunks.append(chunk)\n",
    "    print('\\tfinished file! (%d of %d)'% (counter, len(file_list)))\n",
    "    counter += 1\n",
    "    \n",
    "# concat chunks\n",
    "status = pd.concat(chunks)\n",
    "\n",
    "print('Data Loaded Successfully!')\n",
    "\n",
    "status.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Station Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('Loading Station Data...')\n",
    "\n",
    "try:\n",
    "    file_path_slug = '../../datasets/bayareabikeshare/*_station_data.csv'\n",
    "    \n",
    "    # glob all files\n",
    "    file_list = glob(file_path_slug)\n",
    "    \n",
    "    station = pd.DataFrame()\n",
    "    \n",
    "    counter = 1\n",
    "    chunks = []\n",
    "    \n",
    "    # load data from each file\n",
    "    for file in file_list:\n",
    "        \n",
    "        # import file in chunks\n",
    "        for chunk in pd.read_csv(file, chunksize=10000, iterator=True):\n",
    "            \n",
    "            chunks.append(chunk)\n",
    "            \n",
    "        print('\\tfinished file! (%d of %d)'% (counter, len(file_list)))\n",
    "        counter += 1\n",
    "    \n",
    "    # concat chunks\n",
    "    station = pd.concat(chunks)\n",
    "    \n",
    "    print('Data Loaded Successfully!')\n",
    "except:\n",
    "    print('oops... something went wrong loading the data :()')\n",
    "    \n",
    "station.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "station.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean Trip Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trip = trip.drop_duplicates(keep='first')\n",
    "trip = trip.dropna(how='all')\n",
    "trip.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean Weather Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weather = weather.drop_duplicates(keep='first')\n",
    "weather = weather.dropna(how='all')\n",
    "weather.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean Station Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "station = station.drop_duplicates(keep='first')\n",
    "station = station.dropna(how='all')\n",
    "\n",
    "station['installation'] = pd.to_datetime(station['installation'],infer_datetime_format=True).copy()\n",
    "station['dockcount'] = station['dockcount'].astype('int')\n",
    "station['station_id'] = station['station_id'].astype('int').astype('str')\n",
    "\n",
    "station = station.set_index('station_id')\n",
    "station.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "station.head(90)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean Status Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "status = status.drop_duplicates(keep='first')\n",
    "status = status.dropna(how='all')\n",
    "status.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "status.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "status['total_docks'] = status['bikes_available'] + status['docks_available']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "status.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "status['time'] = pd.to_datetime(status['time'], format='%Y/%m/%d %H:%M:%S').copy()\n",
    "status.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "status['bike_availability_ratio'] = status['bikes_available'] / status['total_docks'] * 100.0\n",
    "\n",
    "status.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# resample to hourly mean by station\n",
    "status_station_grouped = status.groupby(['station_id', status.time.dt.hour*3]).mean()\n",
    "status_station_grouped.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for station in status.station_id.unique():\n",
    "    try:\n",
    "        s = status[status['station_id'] == station]\n",
    "        s.groupby(s.time.dt.hour).mean()['bike_availability_ratio'].plot(figsize=(20,5))\n",
    "        plt.title('Station %s Bike Availability Ratio' % station)\n",
    "        plt.show()\n",
    "        \n",
    "    except:\n",
    "        print('station %s has no data, skipping...' % station)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
