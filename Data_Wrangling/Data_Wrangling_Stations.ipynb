{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Investigation - Stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "import datetime\n",
    "import math\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:95% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "font = {'size'   : 50}\n",
    "matplotlib.rc('font', **font)\n",
    "\n",
    "LABEL_FONT_SIZE = 15\n",
    "TITLE_FONT_SIZE = 25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "FIRST_SERVICE_DATE = datetime.datetime.strptime('2013-08-29', '%Y-%m-%d')\n",
    "LAST_SERVICE_DATE  = datetime.datetime.strptime('2016-08-31', '%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Station Data...\n",
      "\tFinished file! (1 of 4)\n",
      "\tFinished file! (2 of 4)\n",
      "\tFinished file! (3 of 4)\n",
      "\tFinished file! (4 of 4)\n",
      "Data Loaded Successfully!\n"
     ]
    }
   ],
   "source": [
    "print('Loading Station Data...')\n",
    "\n",
    "try:\n",
    "    file_path_slug = '../../../datasets/bayareabikeshare/*_station_data.csv'\n",
    "    file_list = glob(file_path_slug)\n",
    "\n",
    "    station_01 = pd.DataFrame()\n",
    "    station_02 = pd.DataFrame()\n",
    "    station_03 = pd.DataFrame()\n",
    "    station_04 = pd.DataFrame()\n",
    "\n",
    "    counter = 1\n",
    "\n",
    "\n",
    "    for file in file_list:\n",
    "        \n",
    "        chunks = []\n",
    "            \n",
    "        for chunk in pd.read_csv(file, chunksize=10000, iterator=True):\n",
    "            chunk.columns = ['station_id', 'name', 'lat', 'long', 'dock_count', 'landmark', 'first_service_date']            \n",
    "            chunks.append(chunk)\n",
    "        print('\\tFinished file! (%d of %d)' % (counter, len(file_list)))\n",
    "        \n",
    "        if counter == 1:\n",
    "            station_01 = pd.concat(chunks)\n",
    "        elif counter == 2:\n",
    "            station_02 = pd.concat(chunks)\n",
    "        elif counter == 3:\n",
    "            station_03 = pd.concat(chunks)\n",
    "        elif counter == 4:\n",
    "            station_04 = pd.concat(chunks)\n",
    "        else:\n",
    "            pass        \n",
    "\n",
    "        counter += 1\n",
    "\n",
    "    print('Data Loaded Successfully!')\n",
    "except:\n",
    "    print('oops... something went wrong importing the data :(')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1201 entries, 0 to 69\n",
      "Data columns (total 7 columns):\n",
      "station_id            276 non-null float64\n",
      "name                  276 non-null object\n",
      "lat                   276 non-null float64\n",
      "long                  276 non-null float64\n",
      "dock_count            276 non-null float64\n",
      "landmark              276 non-null object\n",
      "first_service_date    276 non-null object\n",
      "dtypes: float64(4), object(3)\n",
      "memory usage: 75.1+ KB\n"
     ]
    }
   ],
   "source": [
    "tmp = pd.concat([station_01, station_02, station_03, station_04])\n",
    "tmp.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preview loaded data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "station_01.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "station_01.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "station_02.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_02.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_03.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "station_03.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_04.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "station_04.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "station_04.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def label_zip(row):\n",
    "    ''' Return zipcode for given landmark\n",
    "    '''\n",
    "    if row['landmark'] == 'San Francisco':\n",
    "       return 94107\n",
    "    if row['landmark'] == 'Redwood City':\n",
    "        return 94063\n",
    "    if row['landmark'] == 'Palo Alto':\n",
    "        return 94301\n",
    "    if row['landmark'] == 'Mountain View':\n",
    "        return 94041\n",
    "    if row['landmark'] == 'San Jose':\n",
    "        return 95113\n",
    "    return 99999\n",
    "\n",
    "def days_in_service(row):\n",
    "    ''' returns an integer of the number of days the statin was in service\n",
    "    '''\n",
    "    days_in_service = row.last_service_date - row.first_service_date\n",
    "    \n",
    "    try:\n",
    "        result = int(days_in_service.days)\n",
    "    except:\n",
    "        result = 999999\n",
    "    \n",
    "    return result\n",
    "\n",
    "def correct_first_service_date(row):\n",
    "    ''' adjust first service dates prior to the program start date\n",
    "    '''\n",
    "    if row.first_service_date < FIRST_SERVICE_DATE:\n",
    "        result = FIRST_SERVICE_DATE\n",
    "    else:\n",
    "        result = row.first_service_date\n",
    "    return result\n",
    "\n",
    "\n",
    "def clean_import_data_types(df):\n",
    "    ''' set the correct datatype for each column on initially imported data\n",
    "    '''\n",
    "    df['station_id']         = df['station_id'].astype('int')\n",
    "    df['name']               = df['name'].astype('str')\n",
    "    df['lat']                = df['lat'].astype('float')\n",
    "    df['long']               = df['long'].astype('float')\n",
    "    df['landmark']           = df['landmark'].astype('category')\n",
    "    df['dock_count']         = df['dock_count'].astype('int')\n",
    "    df['first_service_date'] = pd.to_datetime(df['first_service_date'], format='%m/%d/%Y', errors='coerce')\n",
    "    \n",
    "    return df\n",
    "\n",
    "def clean_final_data_types(df):\n",
    "    ''' set the correct datatype for each column on final pass\n",
    "    '''\n",
    "    df['station_id']         = df['station_id'].astype('int')\n",
    "    df['name']               = df['name'].astype('str')\n",
    "    df['lat']                = df['lat'].astype('float')\n",
    "    df['long']               = df['long'].astype('float')\n",
    "    df['landmark']           = df['landmark'].astype('category')\n",
    "    df['dock_count']         = df['dock_count'].astype('int')\n",
    "    df['first_service_date'] = pd.to_datetime(df['first_service_date'], format='%m/%d/%Y', errors='coerce')\n",
    "    df['last_service_date']  = pd.to_datetime(df['last_service_date'], format='%m/%d/%Y', errors='coerce')\n",
    "    df['zip_code']           = df['zip_code'].astype('str')\n",
    "    df['days_in_service']    = df['days_in_service'].astype('int')\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean Data\n",
    "\n",
    "- Merge Dataframes, drop duplicates\n",
    "- Corrections provided by Bay Area Bike Share Notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stations_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def notes_cleaning(df):\n",
    "    ''' Manual Fixes from included notes in publisehd dataset'''\n",
    "    \n",
    "    index_drop_list = []\n",
    "    \n",
    "    # FROM NOTES - correct installation dates prior to 8/29/13, to 8/29/13\n",
    "        # Cleaning Step : adjust all dates prior to service start dates to FIRST_SERVICE_DATE\n",
    "    df['first_service_date'] = df.apply(lambda row: correct_first_service_date (row), axis=1)\n",
    "\n",
    "    # FROM NOTES - Station 23: From 9/1/14 – 10/22/14: This station was located at (37.488501, -122.231061). \n",
    "        # Cleaning Step : this move is across the block, throw out new location record\n",
    "    index_drop_list.append(17)\n",
    "    df.loc[17, 'station_id'] = 'JUNK'\n",
    "\n",
    "    # FROM NOTES - Station 25: From 9/1/14 – 10/22/14: This station was located at (37.486725, -122.225551). It was previously named “Broadway at Main.”\n",
    "        # Cleaning Step : station is renamed and moved over a mile, set end and start dates for row\n",
    "    df.loc[19,'last_service_date']  = datetime.datetime.strptime('2014-09-01', '%Y-%m-%d')\n",
    "    df.loc[20,'first_service_date'] = datetime.datetime.strptime('2014-09-01', '%Y-%m-%d')\n",
    "\n",
    "    # FROM NOTES - Station 49: From 9/1/14 - 2/5/15: This station was located at (37.789625, -122.390264). \n",
    "        # Cleaning Step : station was moved around the block, throw out new location record\n",
    "    index_drop_list.append(44)\n",
    "    df.loc[44, 'station_id'] = 'JUNK'\n",
    "    \n",
    "    \n",
    "    # FROM NOTES - Station 69: From 9/1/14 – 3/11/15: This station was located at (37.776377,-122.39607). \n",
    "        # Cleaning Step : station was moved around the block, throw out new location record\n",
    "    index_drop_list.append(63)\n",
    "    df.loc[63, 'station_id'] = 'JUNK'\n",
    "        \n",
    "\n",
    "    # FROM NOTES - Station 72: Moved twice. From 9/1/14 – 2/12/15, this station was located at (37.780356, -122.412919). \n",
    "    #                                       From 2/13/15 to 6/3/15, the station was located at (37.780353, -122.41226). \n",
    "        # Cleaning Step : the statio was only relocated once on 2/13/15, not twice.  move was around the corner, toss out latest record\n",
    "    index_drop_list.append(67)\n",
    "    df.loc[67, 'station_id'] = 'JUNK'\n",
    "        \n",
    "\n",
    "    # FROM NOTES - Station 80: On 9/1/14, this station changed names from \"San Jose Government Center\" to \"Santa Clara County Civic Center.\" It did not move.\n",
    "        # Cleaning Step : name change, second name is better, throw out original name\n",
    "    index_drop_list.append(74)\n",
    "    df.loc[74, 'station_id'] = 'JUNK'\n",
    "        \n",
    "\n",
    "    # FROM NOTES - Station 21: On 9/16/15, this station was renamed from \"Franklin at Maple\" to \"Sequoia Hospital\" and moved to (37.479303,-122.253755)\n",
    "        # Cleaning Step : this is a significant move, create a new row, and adjust start and end dates\n",
    "    df.loc[14,'last_service_date']  = datetime.datetime.strptime('2015-09-16', '%Y-%m-%d')\n",
    "    station_21_copy = df.loc[14,:].copy()\n",
    "    station_21_copy.lat = 37.479303\n",
    "    station_21_copy.long = -122.253755\n",
    "    station_21_copy.first_service_date = datetime.datetime.strptime('2015-09-16', '%Y-%m-%d')\n",
    "    station_21_copy.last_service_date = LAST_SERVICE_DATE\n",
    "    df.loc[100] = station_21_copy\n",
    "    df.loc[100, 'name'] = 'Sequoia Hospital'\n",
    "\n",
    "\n",
    "    # FROM NOTES - Station 26: On 9/16/15, this station was renamed from \"Redwood City Medical Center\" to \"Kaiser Hospital\" and moved to (37.489704,-122.224728)\n",
    "        # Cleaning Step :  station was moved around the block, nothing to do here\n",
    "    \n",
    "    \n",
    "    # FROM NOTES - Station 30: On 9/28/15, this station was renamed from \"Evelyn Park and Ride\" to \"Middlefield Light Rail Station\" and moved to (37.395337,-122.052476)\n",
    "        # Cleaning Step : this is a substantial move, update start and end dates\n",
    "    df.loc[25,'last_service_date']  = datetime.datetime.strptime('2015-09-28', '%Y-%m-%d')\n",
    "    df.loc[26,'first_service_date'] = datetime.datetime.strptime('2015-09-28', '%Y-%m-%d')\n",
    "\n",
    "\n",
    "    # FROM NOTES - Station 33: On 9/16/15, this station was renamed from \"Rengstorff Avenue / California Street\" to \"Charleston Park/ North Bayshore Area\" and moved to (37.420909,-122.080623)\n",
    "        # Cleaning Step : this is a substantial move, update start and end dates\n",
    "    df.loc[29,'last_service_date']  = datetime.datetime.strptime('2015-09-16', '%Y-%m-%d')\n",
    "    df.loc[30,'first_service_date'] = datetime.datetime.strptime('2015-09-16', '%Y-%m-%d') \n",
    "\n",
    "\n",
    "    # FROM NOTES - Station 73: Moved twice. From 3/14/16 – 5/19/16, this station was located at (37.797746, -122.407073). From 5/19/16 to 8/31/16, the station was located at (37.7979, -122.405942). The station name stayed the same for all moves. \n",
    "        # Cleaning Step : the move is around the block, but mor stations were added\n",
    "    df.loc[68,'last_service_date']  = datetime.datetime.strptime('2015-05-19', '%Y-%m-%d')\n",
    "    df.loc[69,'first_service_date'] = datetime.datetime.strptime('2015-05-19', '%Y-%m-%d')\n",
    "\n",
    "\n",
    "    # FROM NOTES - Station 83: On 9/16/15, this station was renamed from \"Mezes Park\" to \"Mezes\" and moved to (37.491405,-122.233051)\n",
    "        # Cleaning Step : moved around corner, nothing to clean\n",
    "\n",
    "\n",
    "    # FROM NOTES - Note 2: On 6/30/16, Service in Redwood City was discontinued due to low usage. This included 7 stations: 21, 22, 23, 24, 25, and 26.\n",
    "        # Cleaning Step : set last_service_date on these stations\n",
    "    df.loc[15,'last_service_date']  = datetime.datetime.strptime('2016-06-30', '%Y-%m-%d')\n",
    "    df.loc[16,'last_service_date']  = datetime.datetime.strptime('2016-06-30', '%Y-%m-%d')\n",
    "    df.loc[17,'last_service_date']  = datetime.datetime.strptime('2016-06-30', '%Y-%m-%d')\n",
    "    df.loc[18,'last_service_date']  = datetime.datetime.strptime('2016-06-30', '%Y-%m-%d')\n",
    "    df.loc[19,'last_service_date']  = datetime.datetime.strptime('2016-06-30', '%Y-%m-%d')\n",
    "    df.loc[20,'last_service_date']  = datetime.datetime.strptime('2016-06-30', '%Y-%m-%d')\n",
    "    df.loc[21,'last_service_date']  = datetime.datetime.strptime('2016-06-30', '%Y-%m-%d')\n",
    "    df.loc[77,'last_service_date']  = datetime.datetime.strptime('2016-06-30', '%Y-%m-%d')\n",
    "    df.loc[100,'last_service_date']  = datetime.datetime.strptime('2016-06-30', '%Y-%m-%d')  # station 21 update, special index\n",
    "    \n",
    "\n",
    "    # FROM NOTES - Four of these stations have since been moved to either San Francisco or San Jose. (Stations 23, 24, 25 and 26 have become stations 88, 89, 90 and 91 respectively). Although these stations were promptly re-named, there was a delay in assigning them new station IDs. Full details:\n",
    "        # Cleaning Step \n",
    "\n",
    "\n",
    "    # FROM NOTES - On 7/5/16, Station 23, \"San Mateo County Center,\" was renamed to be \"5th S. at E. San Salvador St.” On 8/24/16, the station was reassigned to Station 88.\n",
    "        # Cleaning Step :  79\n",
    "    df.loc[16, 'last_service_date']  = datetime.datetime.strptime('2016-07-05', '%Y-%m-%d')\n",
    "    df.loc[79,'first_service_date']  = datetime.datetime.strptime('2016-07-05', '%Y-%m-%d')\n",
    "\n",
    "\n",
    "    # FROM NOTES - On 7/5/16, Station 24, \"Redwood City Public Library,\" was renamed to be \"S. Market St at Park Ave.” On 8/24/16, the station was reassigned to Station 89.\n",
    "        # Cleaning Step :  80\n",
    "    df.loc[18, 'last_service_date']  = datetime.datetime.strptime('2016-07-05', '%Y-%m-%d')\n",
    "    df.loc[80,'first_service_date']  = datetime.datetime.strptime('2016-07-05', '%Y-%m-%d')\n",
    "\n",
    "\n",
    "    # FROM NOTES - On 8/4/16, Station 25, \"Stanford in Redwood City,\" was renamed to be \"Cyril Magnin St at Ellis St.” On 8/24/16, the station was reassigned to Station 91.\n",
    "        # Cleaning Step :  82\n",
    "    df.loc[20, 'last_service_date']  = datetime.datetime.strptime('2016-08-04', '%Y-%m-%d')\n",
    "    df.loc[82,'first_service_date']  = datetime.datetime.strptime('2016-08-04', '%Y-%m-%d')\n",
    "\n",
    "\n",
    "    # FROM NOTES - On 8/4/16, Station 26, \"Kaiser Hospital,\" was renamed to be \"5th St at Folsom St.” On 8/24/16, the station was reassigned to Station 90.\n",
    "        # Cleaning Step :  81\n",
    "    df.loc[21, 'last_service_date']  = datetime.datetime.strptime('2016-08-04', '%Y-%m-%d')\n",
    "    df.loc[81,'first_service_date']  = datetime.datetime.strptime('2016-08-04', '%Y-%m-%d')\n",
    "    \n",
    "\n",
    "    # drop all rows in drop list and clean/reset index\n",
    "    df.drop(index_drop_list, inplace=True)\n",
    "    df.sort_values(['station_id', 'first_service_date'], inplace=True)\n",
    "    df.reset_index(inplace=True, drop=True)\n",
    "    \n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_01_TOCLEAN = station_01.copy()\n",
    "station_02_TOCLEAN = station_02.copy()\n",
    "station_03_TOCLEAN = station_03.copy()\n",
    "station_04_TOCLEAN = station_04.copy()\n",
    "\n",
    "# remove dulplicates\n",
    "print('\\tdropping completely empty rows')\n",
    "station_01_TOCLEAN.dropna(how='all', inplace=True)\n",
    "print(station_01_TOCLEAN.shape)\n",
    "station_02_TOCLEAN.dropna(how='all', inplace=True)\n",
    "print(station_02_TOCLEAN.shape)\n",
    "station_03_TOCLEAN.dropna(how='all', inplace=True)\n",
    "print(station_03_TOCLEAN.shape)\n",
    "station_04_TOCLEAN.dropna(how='all', inplace=True)\n",
    "print(station_04_TOCLEAN.shape)\n",
    "\n",
    "# clean imported date types\n",
    "print('\\tsetting column data types')\n",
    "station_01_TOCLEAN = clean_import_data_types(station_01_TOCLEAN)\n",
    "station_02_TOCLEAN = clean_import_data_types(station_02_TOCLEAN)\n",
    "station_03_TOCLEAN = clean_import_data_types(station_03_TOCLEAN)\n",
    "station_04_TOCLEAN = clean_import_data_types(station_04_TOCLEAN)\n",
    "\n",
    "# merge data sets and drop duplicate records\n",
    "print('\\tmerging to single dataframe and droping duplicate rows')\n",
    "station_data_TOCLEAN = pd.concat([station_01_TOCLEAN, station_02_TOCLEAN, station_03_TOCLEAN, station_04_TOCLEAN])\n",
    "station_data_TOCLEAN.drop_duplicates(inplace=True)\n",
    "station_data_TOCLEAN.sort_values('station_id', inplace=True)\n",
    "station_data_TOCLEAN.reset_index(drop=True, inplace=True)\n",
    "\n",
    "print(station_data_TOCLEAN.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_data_TOCLEAN.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('Station Data Cleanup Started...')\n",
    "\n",
    "\n",
    "print('\\tadjusting installatin dates and last service dates')\n",
    "# as a starting point, set 'last_service_date' to LAST_SERVICE_DATE, adjust based on notes\n",
    "station_data_TOCLEAN['last_service_date'] = LAST_SERVICE_DATE\n",
    "\n",
    "station_data_TOCLEAN['zip_code'] = station_data_TOCLEAN.apply(lambda row: label_zip (row),axis=1)\n",
    "\n",
    "print('\\tspecific notes cleaning started')\n",
    "station_data_TOCLEAN = notes_cleaning(station_data_TOCLEAN)\n",
    "\n",
    "print('\\tcalculating days in service')\n",
    "station_data_TOCLEAN['days_in_service'] = station_data_TOCLEAN.apply(lambda row: days_in_service (row),axis=1)\n",
    "\n",
    "# clean data column types a final time\n",
    "print('\\tsetting column data types')\n",
    "station_data_TOCLEAN = clean_final_data_types(station_data_TOCLEAN)\n",
    "\n",
    "station_data = station_data_TOCLEAN.copy()\n",
    "\n",
    "print('Cleaning complete!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_data_TOCLEAN.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preview Final Data Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docks_by_service_area = station_data.groupby('landmark')['dock_count'].count().to_frame()\n",
    "plt.subplots(figsize=(15,6))\n",
    "ax = sns.barplot(x=docks_by_service_area.index, y='dock_count', data=docks_by_service_area)\n",
    "ax.set_title('Total Docks', size=TITLE_FONT_SIZE, weight='bold')\n",
    "ax.set_xlabel('Service Area', size=LABEL_FONT_SIZE, rotation=90)\n",
    "ax.set_xticklabels(sorted(pd.unique(station_data.landmark)), rotation=0)\n",
    "ax.set_ylabel('Number of Docks', size=LABEL_FONT_SIZE)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots(figsize=(15,6))\n",
    "ax = sns.barplot(x='landmark', y='days_in_service', data=station_data)\n",
    "ax.set_title('Days in Service', size=TITLE_FONT_SIZE, weight='bold')\n",
    "ax.set_xlabel('Service Area', size=LABEL_FONT_SIZE)\n",
    "ax.set_ylabel('Number of Docks', size=LABEL_FONT_SIZE)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots(figsize=(15,6))\n",
    "ax = sns.swarmplot(x='landmark', y='dock_count', data=station_data, s=10)\n",
    "ax.set_title('Dock Per Station', size=TITLE_FONT_SIZE, weight='bold')\n",
    "ax.set_xlabel('Service Area', size=LABEL_FONT_SIZE)\n",
    "ax.set_ylabel('Number of Docks', size=LABEL_FONT_SIZE)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "station_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for item in pd.unique(station_data.zip_code):\n",
    "    t = station_data[station_data.zip_code == item]\n",
    "    \n",
    "    if item == '94107':\n",
    "        print('\\nSan Francisco')\n",
    "    if item == '94063':\n",
    "        print('\\nRedwood City')\n",
    "    if item == '94301':\n",
    "        print('\\nPalo Alto')\n",
    "    if item == '94041':\n",
    "        print('\\nMountain View')\n",
    "    if item == '95113':\n",
    "        print('\\nSan Jose')\n",
    "    print('-' * 80)\n",
    "    print(sorted(pd.unique(t.name)))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "San Jose\n",
    "--------------------------------------------------------------------------------\n",
    "['5th S. at E. San Salvador St', 'Adobe on Almaden', 'Arena Green / SAP Center', 'Japantown', 'MLK Library', \n",
    " 'Paseo de San Antonio', 'Ryland Park', 'S. Market st at Park Ave', 'SJSU - San Salvador at 9th', 'SJSU 4th at San Carlos', \n",
    " 'San Jose City Hall', 'San Jose Civic Center', 'San Jose Diridon Caltrain Station', 'San Jose Government Center', 'San Pedro Square', \n",
    " 'San Salvador at 1st', 'Santa Clara at Almaden', 'St James Park']\n",
    "\n",
    "Redwood City\n",
    "--------------------------------------------------------------------------------\n",
    "['Broadway at Main', 'Franklin at Maple', 'Mezes Park',  'Redwood City Medical Center', \n",
    " 'Redwood City Public Library', 'San Mateo County Center', 'Sequoia Hospital', 'Stanford in Redwood City']\n",
    "\n",
    "Mountain View\n",
    "--------------------------------------------------------------------------------\n",
    "['Castro Street and El Camino Real', 'Charleston Park/ North Bayshore Area', 'Evelyn Park and Ride', \n",
    " 'Middlefield Light Rail Station',  'Mountain View City Hall', 'Rengstorff Avenue / California Street', \n",
    " 'San Antonio Caltrain Station', 'San Antonio Shopping Center']\n",
    "\n",
    "Palo Alto\n",
    "--------------------------------------------------------------------------------\n",
    "[, 'Cowper at University', , 'Park at Olive', \n",
    " 'University and Emerson']\n",
    "\n",
    "San Francisco\n",
    "--------------------------------------------------------------------------------\n",
    "['2nd at Folsom', '2nd at South Park', '2nd at Townsend', '5th St at Folsom St', '5th at Howard', 'Beale at Market', \n",
    " 'Broadway St at Battery St', , 'Clay at Battery', 'Commercial at Montgomery', \n",
    " 'Cyril Magnin St at Ellis St', 'Davis at Jackson', , 'Golden Gate at Polk', 'Grant Avenue at Columbus Avenue',  \n",
    " 'Howard at 2nd', 'Market at 10th', 'Market at 4th', 'Market at Sansome', 'Mechanics Plaza (Market at Battery)', 'Post at Kearney', \n",
    "  'Powell at Post (Union Square)',  \n",
    " 'San Francisco City Hall', 'South Van Ness at Market', 'Spear at Folsom', 'Steuart at Market',  \n",
    " 'Townsend at 7th', 'Washington at Kearney', 'Yerba Buena Center of the Arts (3rd @ Howard)']\n",
    "\n",
    "\n",
    "\n",
    "caltrian_stations = ['San Francisco Caltrain (Townsend at 4th)', 'San Francisco Caltrain 2 (330 Townsend)', 'Redwood City Caltrain Station', 'Mountain View Caltrain Station', 'California Ave Caltrain Station', 'Palo Alto Caltrain Station']\n",
    "\n",
    "mass_transit_stations = ['Powell Street BART', 'Civic Center BART (7th at Market)', 'Harry Bridges Plaza (Ferry Building)', 'Temporary Transbay Terminal (Howard at Beale)',]\n",
    "\n",
    "embarcadero_stations  = ['Embarcadero at Bryant', 'Embarcadero at Folsom', 'Embarcadero at Sansome', 'Embarcadero at Vallejo']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def label_commuter (row):\n",
    "    \n",
    "    \n",
    "\n",
    "   if row['name'] == 1 :\n",
    "      return True\n",
    "   return False\n",
    "\n",
    "\n",
    "station_data['is_commuter'] = station_data.apply (lambda row: label_commuter (row),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_data[:45]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_data[45:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Write to File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "station_data.to_csv('../clean_data/station_data_cleaned_final.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick Reference to Special Stations\n",
    "\n",
    "> Stations that kept their station_id but other information changed, mostly location, one is dock count\n",
    "\n",
    "> All Stations in Redwood City were closed on June 30, 2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "specials = station_data[station_data.duplicated(subset=['station_id'], keep=False)]\n",
    "specials.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "redwood_city = station_data[station_data.landmark == 'Redwood City']\n",
    "redwood_city.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Quick Preview All Station Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "redwoodCity_stations = sorted(pd.unique(station_data[station_data.landmark == 'Redwood City']['station_id']))\n",
    "print('redwoodCity_stations =', redwoodCity_stations)\n",
    "mountainView_stations = sorted(pd.unique(station_data[station_data.landmark == 'Mountain View']['station_id']))\n",
    "print('mountainView_stations =', mountainView_stations)\n",
    "sanJose_stations = sorted(pd.unique(station_data[station_data.landmark == 'San Jose']['station_id']))\n",
    "print('sanJose_stations =', sanJose_stations)\n",
    "sanFrancisco_stations = sorted(pd.unique(station_data[station_data.landmark == 'San Francisco']['station_id']))\n",
    "print('sanFrancisco_stations =', sanFrancisco_stations)\n",
    "paloAlto_stations = sorted(pd.unique(station_data[station_data.landmark == 'Palo Alto']['station_id']))\n",
    "print('paloAlto_stations =', paloAlto_stations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
