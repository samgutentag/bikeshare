{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Wrangling - Trips"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "import datetime\n",
    "import math\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:95% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "font = {'size'   : 50}\n",
    "matplotlib.rc('font', **font)\n",
    "\n",
    "LABEL_FONT_SIZE = 15\n",
    "TITLE_FONT_SIZE = 25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Trip Data...\n",
      "Data Loaded Successfully!\n"
     ]
    }
   ],
   "source": [
    "print('Loading Trip Data...')\n",
    "\n",
    "try:\n",
    "    file_path_slug = '../../../datasets/cogobikeshare/*_trip_data.csv'\n",
    "\n",
    "    # glob all files\n",
    "    file_list = glob(file_path_slug)\n",
    "\n",
    "    counter = 1\n",
    "\n",
    "    # load data from each file\n",
    "    for file in file_list:\n",
    "\n",
    "        chunks = []\n",
    "        chunk_counter = 1\n",
    "        chunksize = 10000\n",
    "        num_chunks = math.ceil(sum(1 for row in open(file, 'r'))/chunksize)\n",
    "\n",
    "        # import file in chunks\n",
    "        for chunk in pd.read_csv(file, chunksize=chunksize, iterator=True):\n",
    "\n",
    "            # define Columns\n",
    "            chunk.columns = ['trip_id', 'duration', 'start_date', 'start_station_name', 'start_terminal', 'end_date', \n",
    "                             'end_station_name', 'end_terminal', 'bike_id', 'subscriber_type', 'zip_code']\n",
    "\n",
    "            # append chunk to chunks list\n",
    "            chunks.append(chunk)\n",
    "            \n",
    "            if chunk_counter == 1 or chunk_counter % math.ceil(num_chunks/10) == 0 or chunk_counter == num_chunks:\n",
    "                print('\\t[%s] finished chunk %s of %s' % (datetime.datetime.now().time(), chunk_counter, num_chunks))\n",
    "            chunk_counter += 1\n",
    "            \n",
    "\n",
    "        if counter == 1:\n",
    "            trip_import_01 = pd.DataFrame()\n",
    "            trip_import_01 = pd.concat(chunks)\n",
    "        elif counter == 2:\n",
    "            trip_import_02 = pd.DataFrame()\n",
    "            trip_import_02 = pd.concat(chunks)\n",
    "        elif counter == 3:\n",
    "            trip_import_03 = pd.DataFrame()\n",
    "            trip_import_03 = pd.concat(chunks)\n",
    "        elif counter == 4:\n",
    "            trip_import_04 = pd.DataFrame()\n",
    "            trip_import_04 = pd.concat(chunks)\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "\n",
    "        print('Finished file! (%d of %d)' % (counter, len(file_list)))\n",
    "        counter += 1\n",
    "\n",
    "    print('Data Loaded Successfully!')\n",
    "\n",
    "except:\n",
    "    print('oops... something went wrong importing the data :(')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trip_import_01' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-37c6fd2d15e1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrip_import_01\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'trip_import_01' is not defined"
     ]
    }
   ],
   "source": [
    "trip_import_01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trip_import_01.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# zipcodes are all over the place, only keep corrected 5 digit zipcodes, and replace all others with NaNs\n",
    "def clean_zipcode(item):\n",
    "    \n",
    "    z = str(item)\n",
    "    \n",
    "    if len(z) != 5:\n",
    "\n",
    "        # split on '-'\n",
    "        try:\n",
    "            result = z.split('-')[0]\n",
    "        except:\n",
    "            result = z\n",
    "\n",
    "        # split on '.'\n",
    "        try:\n",
    "            result = z.split('.')[0]\n",
    "        except:\n",
    "            result = z\n",
    "        \n",
    "        # if len of item is less than 5, return 'NaN'\n",
    "        if len(result) < 5:\n",
    "            result = 'NaN'\n",
    "        else:\n",
    "            # if len result is greater than 5, take at most, first 5 digits\n",
    "            result = result[:5]\n",
    "    else:\n",
    "        result = z\n",
    "    \n",
    "    # make sure result is all digits\n",
    "    if result.isdigit():\n",
    "        result = int(result)\n",
    "        return result\n",
    "    else:\n",
    "        return 99999\n",
    "    \n",
    "def clean_trip_frame(df):\n",
    "    \n",
    "    # set column types\n",
    "    df['start_date']       = pd.to_datetime(df['start_date'], format=\"%m/%d/%Y %H:%M\")\n",
    "    df['end_date']         = pd.to_datetime(df['end_date'],   format=\"%m/%d/%Y %H:%M\")\n",
    "    df['trip_id']          = df['trip_id'].astype('int')\n",
    "    df['duration']         = df['duration'].astype('int')    \n",
    "    df['start_terminal']   = df['start_terminal'].astype('int')\n",
    "    df['end_terminal']     = df['end_terminal'].astype('int')\n",
    "    df['bike_id']          = df['bike_id'].astype('int')\n",
    "    df['subscriber_type']  = df['subscriber_type'].astype('category')\n",
    "    \n",
    "    # add 'duration_minutes' column\n",
    "    df['duration_minutes'] = df['duration'] / 60.\n",
    "    df['duration_minutes'] = df['duration_minutes'].astype('float')\n",
    "    \n",
    "    # Clean Zipcode\n",
    "    df['zip_code'] = df.zip_code.apply(clean_zipcode)\n",
    "    \n",
    "    # rename columns for clarity\n",
    "    df.rename(columns={'zip_code': 'user_zip', 'subscriber_type': 'user_type'}, inplace=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "def plot_terminal_trips(df, id, date_range = (pd.Timestamp('2013-08-01'), pd.Timestamp('2016-10-01')), x_label = 'Date', y_label = 'Trips', title_suffix='', draw_dates=[]):\n",
    "    \n",
    "    def group_terminal(df, start=True):\n",
    "        ''' group by start or end terminal trips per day\n",
    "        '''\n",
    "        \n",
    "        term = pd.DataFrame()\n",
    "        if start:\n",
    "            term = df[df['start_terminal'] == id]\n",
    "        else:\n",
    "            term = df[df['end_terminal'] == id]\n",
    "        term.set_index('start_date', inplace=True)\n",
    "        g_term = term.groupby(term.index.date)['trip_id'].count()\n",
    "        \n",
    "        return g_term\n",
    "    \n",
    "        \n",
    "    start_term = group_terminal(df, start=True)\n",
    "    end_term   = group_terminal(df, start=False)\n",
    "    \n",
    "    ax = start_term.plot(kind='line', color='c', alpha=0.75, figsize=(24,3))\n",
    "    end_term.plot(kind='line', color='g', alpha=0.75, ax=ax)\n",
    "    \n",
    "    ax.set_xlim(date_range)\n",
    "    if title_suffix != '':\n",
    "        title = 'Station %s - %s' % (id, title_suffix)\n",
    "    elif y_label != '':\n",
    "        title = 'Station %s - %s' % (id, y_label)\n",
    "    else:\n",
    "        title = 'Station %s' % id\n",
    "    ax.set_title(title, size=TITLE_FONT_SIZE, weight='bold')\n",
    "    ax.set_xlabel(x_label, size=LABEL_FONT_SIZE, weight='bold')\n",
    "    ax.set_ylabel(y_label, size=LABEL_FONT_SIZE, weight='bold')\n",
    "    \n",
    "    ax.legend(['Start Terminal', 'End Terminal'], loc=1)\n",
    "    \n",
    "    if len(draw_dates) > 0:\n",
    "        for xc in draw_dates:\n",
    "            ax.axvline(x=xc, color='k', linestyle=':', alpha=0.5)\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "def date_fixes(df, old_terminal, new_terminal, change_date):\n",
    "    \n",
    "    print('[%s]\\tUpdating %s to %s for dates after %s' % (datetime.datetime.now().time(), old_terminal, new_terminal, change_date))\n",
    "\n",
    "#     t_min = pd.Timestamp('2013-05-01')\n",
    "#     t_max = pd.Timestamp('2016-10-01')\n",
    "    \n",
    "    for station in [old_terminal, new_terminal]:\n",
    "        plot_terminal_trips(df, station, title_suffix='PRE DATE FIX', draw_dates=[change_date])\n",
    "        \n",
    "    # Fix A to B - Start Terminal\n",
    "    print('[%s]\\tStarted indexing...' % datetime.datetime.now().time())\n",
    "    index_to_update_start = df[(df.start_terminal == old_terminal) & (df.start_date >= change_date)].index\n",
    "    df.loc[index_to_update_start, 'start_terminal'] = new_terminal\n",
    "    print('\\t[%s]\\tComplete!' % datetime.datetime.now().time())    \n",
    "\n",
    "    # Fix A to B - End Terminal\n",
    "    print('[%s]\\tStarted Update...' % datetime.datetime.now().time())\n",
    "    index_to_update_end   = df[(df.end_terminal == old_terminal) & (df.end_date >= change_date)].index\n",
    "    df.loc[index_to_update_end, 'end_terminal'] = new_terminal\n",
    "    print('\\t[%s]\\tComplete!' % datetime.datetime.now().time())\n",
    "    \n",
    "    \n",
    "    # Fix B to A - Start Terminal\n",
    "    print('[%s]\\tStarted indexing...' % datetime.datetime.now().time())\n",
    "    index_to_update_start = df[(df.start_terminal == new_terminal) & (df.start_date < change_date)].index\n",
    "    df.loc[index_to_update_start, 'start_terminal'] = old_terminal\n",
    "    print('\\t[%s]\\tComplete!' % datetime.datetime.now().time())    \n",
    "\n",
    "    # Fix B to A - End Terminal\n",
    "    print('[%s]\\tStarted Update...' % datetime.datetime.now().time())\n",
    "    index_to_update_end   = df[(df.end_terminal == new_terminal) & (df.end_date < change_date)].index\n",
    "    df.loc[index_to_update_end, 'end_terminal'] = old_terminal\n",
    "    print('\\t[%s]\\tComplete!' % datetime.datetime.now().time())\n",
    "    \n",
    "\n",
    "    for station in [old_terminal, new_terminal]:\n",
    "        plot_terminal_trips(df, station, draw_dates=[change_date])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean Data\n",
    "\n",
    "- Format zip codes to take only first 5 digits, this data is self reported and often wrongly input per Bay Area Bike Share Notes\n",
    "- Prune out Trips greater than 60 minutes long\n",
    "- Adjust records for station relocations and renaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean data frames\n",
    "print('[%s] Trip Data Cleanup Started' % datetime.datetime.now().time())\n",
    "trip_01_clean = clean_trip_frame(trip_import_01.copy())\n",
    "trip_02_clean = clean_trip_frame(trip_import_02.copy())\n",
    "trip_03_clean = clean_trip_frame(trip_import_03.copy())\n",
    "trip_04_clean = clean_trip_frame(trip_import_04.copy())\n",
    "\n",
    "print('[%s] Merging Trip Data' % datetime.datetime.now().time())\n",
    "trip_data = pd.DataFrame()\n",
    "trip_data = pd.concat([trip_01_clean, trip_02_clean, trip_03_clean, trip_04_clean])\n",
    "trip_data.drop_duplicates(inplace=True)\n",
    "trip_data.sort_values('trip_id', inplace=True)\n",
    "trip_data.reset_index(inplace=True, drop=True)\n",
    "\n",
    "print('[%s] Cleanup Complete!' % datetime.datetime.now().time())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trip_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trip_data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trip_data.tail(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prune By Trip Duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prune data to exclude trips longer than 60 minutes\n",
    "print('[%s] - Removing trips longer than 60 minutes' % (datetime.datetime.now().time()))\n",
    "drop_list = trip_data[trip_data.duration_minutes > 60.0].index\n",
    "print('\\t\\tremoving %s items' % len(drop_list))\n",
    "trip_data.drop(drop_list, inplace=True)\n",
    "trip_data.reset_index(inplace=True, drop=True)\n",
    "print('[%s] - Complete' % (datetime.datetime.now().time()))\n",
    "\n",
    "trip_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correct Relocated Stations\n",
    "\n",
    "> There was a delay in station_id updates when stations 23, 24, 25, and 26 were relocated, update status information by changing the station_id for these stations in dates after they were relocated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "change_date = datetime.datetime.strptime('2016-07-05', '%Y-%m-%d')\n",
    "trip_data = date_fixes(trip_data, 23, 88, change_date)\n",
    "trip_data = date_fixes(trip_data, 24, 89, change_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "change_date = datetime.datetime.strptime('2016-08-04', '%Y-%m-%d')\n",
    "trip_data = date_fixes(trip_data, 25, 91, change_date)\n",
    "trip_data = date_fixes(trip_data, 26, 90, change_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preview Graphical EDA by User Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "x_ticks = sorted(pd.unique(trip_data.start_date.dt.hour))\n",
    "subscriber_y = trip_data[trip_data.user_type == 'Subscriber'].groupby(trip_data.start_date.dt.hour)['trip_id'].count()\n",
    "customer_y   = trip_data[trip_data.user_type == 'Customer'].groupby(trip_data.start_date.dt.hour)['trip_id'].count()\n",
    "sub_norm  = subscriber_y.to_frame().apply(lambda x: x / (np.max(x) - np.min(x)))\n",
    "cust_norm =   customer_y.to_frame().apply(lambda x: x / (np.max(x) - np.min(x)))\n",
    "\n",
    "\n",
    "plt.subplots(figsize=(24,6))\n",
    "ax = sns.barplot(x = x_ticks , y = subscriber_y, color='b', alpha = 0.5, label='Subscribers')\n",
    "sns.barplot(x = x_ticks , y = customer_y, color='r', alpha = 0.5, label='Customers', ax=ax)\n",
    "\n",
    "ax.set_title('Distribution of Trips by Hour', size=TITLE_FONT_SIZE, weight='bold')\n",
    "ax.set_xlabel('Start Hour', size=LABEL_FONT_SIZE, weight='bold')\n",
    "ax.set_ylabel('Total Trips', size=LABEL_FONT_SIZE, weight='bold')\n",
    "ax.set_xticks(x_ticks)\n",
    "\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "plt.subplots(figsize=(24,6))\n",
    "ax = sns.barplot(x = x_ticks , y = sub_norm['trip_id'], color='b', alpha = 0.5, label='Subscribers')\n",
    "sns.barplot(x = x_ticks , y = cust_norm['trip_id'], color='r', alpha = 0.5, label='Customers', ax=ax)\n",
    "\n",
    "ax.set_title('Distribution of Trips by Hour (Normalized)', size=TITLE_FONT_SIZE, weight='bold')\n",
    "ax.set_xlabel('Start Hour', size=LABEL_FONT_SIZE, weight='bold')\n",
    "ax.set_ylabel('Distribution', size=LABEL_FONT_SIZE, weight='bold')\n",
    "ax.set_xticks(x_ticks)\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('[%s]\\tWriting File...' % datetime.datetime.now().time())\n",
    "trip_data.to_csv('../clean_data/trip_data_cleaned.csv', encoding='utf-8')\n",
    "print('\\t[%s]\\tComplete!' % datetime.datetime.now().time())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Station Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_data = pd.DataFrame()\n",
    "station_data = pd.read_csv('../clean_data/station_data_cleaned_final.csv', parse_dates=['first_service_date', 'last_service_date'], index_col=0)\n",
    "\n",
    "station_data_basic = pd.DataFrame()\n",
    "# drop duplicated station_id ros, keep first\n",
    "station_data_basic = station_data.copy()\n",
    "station_data_basic.drop_duplicates(subset=['station_id'], keep='first', inplace=True)\n",
    "\n",
    "station_data_basic.drop(['lat', 'long', 'landmark', 'zip_code'], axis=1, inplace=True)\n",
    "\n",
    "station_data_basic.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Append Service area start and end columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trip_data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('[%s]\\tStarting Area Lookup...' % datetime.datetime.now().time())\n",
    "trip_data['start_area'] = trip_data['start_terminal'].apply(lambda x: station_data[station_data.station_id == x]['landmark'].iloc[0])\n",
    "print('\\t[%s]\\tComplete!' % datetime.datetime.now().time())\n",
    "\n",
    "print('[%s]\\tStarting Area Lookup...' % datetime.datetime.now().time())\n",
    "trip_data['end_area'] = trip_data['end_terminal'].apply(lambda x: station_data[station_data.station_id == x]['landmark'].iloc[0])\n",
    "print('\\t[%s]\\tComplete!' % datetime.datetime.now().time())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('[%s]\\tStarting Area Lookup...' % datetime.datetime.now().time())\n",
    "trip_data['start_zip'] = trip_data['start_terminal'].apply(lambda x: station_data[station_data.station_id == x]['zip_code'].iloc[0])\n",
    "print('\\t[%s]\\tComplete!' % datetime.datetime.now().time())\n",
    "\n",
    "print('[%s]\\tStarting Area Lookup...' % datetime.datetime.now().time())\n",
    "trip_data['end_zip'] = trip_data['end_terminal'].apply(lambda x: station_data[station_data.station_id == x]['zip_code'].iloc[0])\n",
    "print('\\t[%s]\\tComplete!' % datetime.datetime.now().time())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review Special Circumstance Stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Station 26 Review\n",
    "s26_dates = ['2013-08-29', '2016-08-04']\n",
    "plot_terminal_trips(trip_data, 26, x_label = 'Date', y_label = 'Trips', title_suffix='Review', draw_dates=s26_dates)\n",
    "\n",
    "# Station 30 Review\n",
    "s30_dates = ['2013-08-29', '2015-09-28', '2016-08-31']\n",
    "plot_terminal_trips(trip_data, 30, x_label = 'Date', y_label = 'Trips', title_suffix='Review', draw_dates=s30_dates)\n",
    "\n",
    "# Station 33 Review\n",
    "s33_dates = ['2013-08-29', '2015-09-16', '2016-08-31']\n",
    "plot_terminal_trips(trip_data, 33, x_label = 'Date', y_label = 'Trips', title_suffix='Review', draw_dates=s33_dates)\n",
    "\n",
    "# Station 73 Review\n",
    "s73_dates = ['2013-08-29', '2015-05-19', '2016-08-31']\n",
    "plot_terminal_trips(trip_data, 73,x_label = 'Date', y_label = 'Trips', title_suffix='Review', draw_dates=s73_dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trip_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trip_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('[%s]\\tWriting File...' % datetime.datetime.now().time())\n",
    "trip_data.to_csv('../clean_data/trip_data_cleaned_zips.csv', encoding='utf-8')\n",
    "print('\\t[%s]\\tComplete!' % datetime.datetime.now().time())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Weather Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weather_data = pd.DataFrame()\n",
    "weather_data = pd.read_csv('../clean_data/weather_cleaned_all.csv', parse_dates=['date'], index_col=['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.unique(weather_data.events)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Append Weather Data to Trips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trip_data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('[%s]\\tAppending Weather Data...' % datetime.datetime.now().time())\n",
    "\n",
    "\n",
    "trip_data = pd.merge(trip_data, \n",
    "                      weather_data, \n",
    "                      how='left', \n",
    "                      left_on=[trip_data['start_date'].dt.date, 'start_zip'], \n",
    "                      right_on=[weather_data.index.date, 'zip_code'])\n",
    "trip_data.drop(['zip_code'], axis=1, inplace=True)\n",
    "# test.set_index('Trip ID', inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print('\\t[%s]\\tComplete!' % datetime.datetime.now().time())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trip_data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trip_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trip_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trip_data.to_csv('../clean_data/trip_data_cleaned_master.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
