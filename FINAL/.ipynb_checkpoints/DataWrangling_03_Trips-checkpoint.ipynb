{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wrangling Data From Bay Area Bike Share Published Data - Trips"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "import datetime\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> Set some notebook variables, makes the norebook 95% width of the screen for easier viewing</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:95% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> Set some global font sizes for plots </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "font = {'size'   : 50}\n",
    "matplotlib.rc('font', **font)\n",
    "\n",
    "LABEL_FONT_SIZE = 15\n",
    "TITLE_FONT_SIZE = 25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Started Loading Station Data...')\n",
    "file_path_slug = '../source_data/*_trip_data.csv'\n",
    "file_list = glob(file_path_slug)\n",
    "\n",
    "trips_df = pd.DataFrame()\n",
    "\n",
    "counter = 1\n",
    "chunks = []\n",
    "\n",
    "for file in file_list:\n",
    "    chunk_counter = 1\n",
    "    num_chunks\n",
    "\n",
    "    for chunk in pd.read_csv(file, chunksize=10000, iterator=True):\n",
    "        chunk.columns = ['station_id', 'name', 'lat', 'long', 'dock_count', 'landmark', 'first_service_date']\n",
    "        chunks.append(chunk)\n",
    "        \n",
    "    print('\\tFinished file! (%d of %d)' % (counter, len(file_list)))\n",
    "    counter += 1\n",
    "    \n",
    "stations_df = pd.concat(chunks)\n",
    "print('Data Loaded Successfully!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanng Support Functions\n",
    "<p>General Cleaning functions</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_data_types(df):\n",
    "    ''' given a station dataframe, clean pu the datatype for each column '''\n",
    "    \n",
    "    # these data columns are included in the imported data set\n",
    "    df['station_id']         = df['station_id'].astype('int')\n",
    "    df['name']               = df['name'].astype('str')\n",
    "    df['lat']                = df['lat'].astype('float')\n",
    "    df['long']               = df['long'].astype('float')\n",
    "    df['landmark']           = df['landmark'].astype('category')\n",
    "    df['dock_count']         = df['dock_count'].astype('int')\n",
    "    df['first_service_date'] = pd.to_datetime(df['first_service_date'], format='%m/%d/%Y', errors='coerce')\n",
    "    \n",
    "    \n",
    "    # these data columns are added through the cleaning process, onyl clean them if they exist\n",
    "    try:\n",
    "        df['last_service_date']  = pd.to_datetime(df['last_service_date'], format='%m/%d/%Y', errors='coerce')\n",
    "        df['zip_code']           = df['zip_code'].astype('str')\n",
    "        df['days_in_service']    = df['days_in_service'].astype('int')\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    return df\n",
    "\n",
    "def landmark_to_zip(row):\n",
    "    ''' Return zipcode for given landmark'''\n",
    "    if row['landmark'] == 'San Francisco':\n",
    "       return 94107\n",
    "    if row['landmark'] == 'Redwood City':\n",
    "        return 94063\n",
    "    if row['landmark'] == 'Palo Alto':\n",
    "        return 94301\n",
    "    if row['landmark'] == 'Mountain View':\n",
    "        return 94041\n",
    "    if row['landmark'] == 'San Jose':\n",
    "        return 95113\n",
    "    return 99999\n",
    "\n",
    "\n",
    "def correct_first_service_date(row):\n",
    "    ''' adjust first service dates which are prior to the program start date'''\n",
    "    if row.first_service_date < FIRST_SERVICE_DATE:\n",
    "        result = FIRST_SERVICE_DATE\n",
    "    else:\n",
    "        result = row.first_service_date\n",
    "    return result\n",
    "\n",
    "\n",
    "def days_in_service(row):\n",
    "    ''' returns an integer of the number of days the statin was in service'''\n",
    "    days_in_service = row.last_service_date - row.first_service_date\n",
    "    \n",
    "    try:\n",
    "        result = int(days_in_service.days)\n",
    "    except:\n",
    "        result = 999999\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Station Data Cleanup Started...')\n",
    "# drop na values and drop duplicates\n",
    "stations_df.dropna(how='all', inplace=True)\n",
    "stations_df.drop_duplicates(inplace=True)\n",
    "\n",
    "\n",
    "# cleanup data types\n",
    "stations_df = clean_data_types(stations_df)\n",
    "\n",
    "# sort by 'station_id' and rest index\n",
    "stations_df.sort_values('station_id', inplace=True)\n",
    "stations_df.reset_index(drop=True, inplace=True)\n",
    "print('\\tStation Data Cleanup Complete!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add some Columns\n",
    "<p> Appending columns of data from other data sets, or from computations on given data.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# add 'last_service_date' column to coenside with last data from data\n",
    "stations_df['last_service_date'] = LAST_SERVICE_DATE\n",
    "\n",
    "# add 'zipcode' column to station, this is handy for cross comparison to other datasets\n",
    "stations_df['zip_code'] = stations_df.apply(lambda row: landmark_to_zip (row), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Special Cleaning Notes\n",
    "<p>This data set is not so large that some cleaning is more easily done manually from notes included from Bay Area Bike Share.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_from_notes(df):\n",
    "    ''' Manual Fixes from included notes in publisehd dataset'''\n",
    "    \n",
    "    index_drop_list = []\n",
    "    \n",
    "    # FROM NOTES - correct installation dates prior to 8/29/13, to 8/29/13\n",
    "        # Cleaning Step : adjust all dates prior to service start dates to FIRST_SERVICE_DATE\n",
    "    df['first_service_date'] = df.apply(lambda row: correct_first_service_date (row), axis=1)\n",
    "\n",
    "    # FROM NOTES - Station 23: From 9/1/14 – 10/22/14: This station was located at (37.488501, -122.231061). \n",
    "        # Cleaning Step : this move is across the block, throw out new location record\n",
    "    index_drop_list.append(17)\n",
    "    df.loc[17, 'station_id'] = 'JUNK'\n",
    "\n",
    "    # FROM NOTES - Station 25: From 9/1/14 – 10/22/14: This station was located at (37.486725, -122.225551). It was previously named “Broadway at Main.”\n",
    "        # Cleaning Step : station is renamed and moved over a mile, set end and start dates for row\n",
    "    df.loc[19,'last_service_date']  = datetime.datetime.strptime('2014-09-01', '%Y-%m-%d')\n",
    "    df.loc[20,'first_service_date'] = datetime.datetime.strptime('2014-09-01', '%Y-%m-%d')\n",
    "\n",
    "    # FROM NOTES - Station 49: From 9/1/14 - 2/5/15: This station was located at (37.789625, -122.390264). \n",
    "        # Cleaning Step : station was moved around the block, throw out new location record\n",
    "    index_drop_list.append(44)\n",
    "    df.loc[44, 'station_id'] = 'JUNK'\n",
    "    \n",
    "    \n",
    "    # FROM NOTES - Station 69: From 9/1/14 – 3/11/15: This station was located at (37.776377,-122.39607). \n",
    "        # Cleaning Step : station was moved around the block, throw out new location record\n",
    "    index_drop_list.append(63)\n",
    "    df.loc[63, 'station_id'] = 'JUNK'\n",
    "        \n",
    "\n",
    "    # FROM NOTES - Station 72: Moved twice. From 9/1/14 – 2/12/15, this station was located at (37.780356, -122.412919). \n",
    "    #                                       From 2/13/15 to 6/3/15, the station was located at (37.780353, -122.41226). \n",
    "        # Cleaning Step : the statio was only relocated once on 2/13/15, not twice.  move was around the corner, toss out latest record\n",
    "    index_drop_list.append(67)\n",
    "    df.loc[67, 'station_id'] = 'JUNK'\n",
    "        \n",
    "\n",
    "    # FROM NOTES - Station 80: On 9/1/14, this station changed names from \"San Jose Government Center\" to \"Santa Clara County Civic Center.\" It did not move.\n",
    "        # Cleaning Step : name change, second name is better, throw out original name\n",
    "    index_drop_list.append(74)\n",
    "    df.loc[74, 'station_id'] = 'JUNK'\n",
    "        \n",
    "\n",
    "    # FROM NOTES - Station 21: On 9/16/15, this station was renamed from \"Franklin at Maple\" to \"Sequoia Hospital\" and moved to (37.479303,-122.253755)\n",
    "        # Cleaning Step : this is a significant move, create a new row, and adjust start and end dates\n",
    "    df.loc[14,'last_service_date']  = datetime.datetime.strptime('2015-09-16', '%Y-%m-%d')\n",
    "    station_21_copy = df.loc[14,:].copy()\n",
    "    station_21_copy.lat = 37.479303\n",
    "    station_21_copy.long = -122.253755\n",
    "    station_21_copy.first_service_date = datetime.datetime.strptime('2015-09-16', '%Y-%m-%d')\n",
    "    station_21_copy.last_service_date = LAST_SERVICE_DATE\n",
    "    df.loc[100] = station_21_copy\n",
    "    df.loc[100, 'name'] = 'Sequoia Hospital'\n",
    "\n",
    "\n",
    "    # FROM NOTES - Station 26: On 9/16/15, this station was renamed from \"Redwood City Medical Center\" to \"Kaiser Hospital\" and moved to (37.489704,-122.224728)\n",
    "        # Cleaning Step :  station was moved around the block, nothing to do here\n",
    "    \n",
    "    \n",
    "    # FROM NOTES - Station 30: On 9/28/15, this station was renamed from \"Evelyn Park and Ride\" to \"Middlefield Light Rail Station\" and moved to (37.395337,-122.052476)\n",
    "        # Cleaning Step : this is a substantial move, update start and end dates\n",
    "    df.loc[25,'last_service_date']  = datetime.datetime.strptime('2015-09-28', '%Y-%m-%d')\n",
    "    df.loc[26,'first_service_date'] = datetime.datetime.strptime('2015-09-28', '%Y-%m-%d')\n",
    "\n",
    "\n",
    "    # FROM NOTES - Station 33: On 9/16/15, this station was renamed from \"Rengstorff Avenue / California Street\" to \"Charleston Park/ North Bayshore Area\" and moved to (37.420909,-122.080623)\n",
    "        # Cleaning Step : this is a substantial move, update start and end dates\n",
    "    df.loc[29,'last_service_date']  = datetime.datetime.strptime('2015-09-16', '%Y-%m-%d')\n",
    "    df.loc[30,'first_service_date'] = datetime.datetime.strptime('2015-09-16', '%Y-%m-%d') \n",
    "\n",
    "\n",
    "    # FROM NOTES - Station 73: Moved twice. From 3/14/16 – 5/19/16, this station was located at (37.797746, -122.407073). From 5/19/16 to 8/31/16, the station was located at (37.7979, -122.405942). The station name stayed the same for all moves. \n",
    "        # Cleaning Step : the move is around the block, but mor stations were added\n",
    "    df.loc[68,'last_service_date']  = datetime.datetime.strptime('2015-05-19', '%Y-%m-%d')\n",
    "    df.loc[69,'first_service_date'] = datetime.datetime.strptime('2015-05-19', '%Y-%m-%d')\n",
    "\n",
    "\n",
    "    # FROM NOTES - Station 83: On 9/16/15, this station was renamed from \"Mezes Park\" to \"Mezes\" and moved to (37.491405,-122.233051)\n",
    "        # Cleaning Step : moved around corner, nothing to clean\n",
    "\n",
    "\n",
    "    # FROM NOTES - Note 2: On 6/30/16, Service in Redwood City was discontinued due to low usage. This included 7 stations: 21, 22, 23, 24, 25, and 26.\n",
    "        # Cleaning Step : set last_service_date on these stations\n",
    "    df.loc[15,'last_service_date']  = datetime.datetime.strptime('2016-06-30', '%Y-%m-%d')\n",
    "    df.loc[16,'last_service_date']  = datetime.datetime.strptime('2016-06-30', '%Y-%m-%d')\n",
    "    df.loc[17,'last_service_date']  = datetime.datetime.strptime('2016-06-30', '%Y-%m-%d')\n",
    "    df.loc[18,'last_service_date']  = datetime.datetime.strptime('2016-06-30', '%Y-%m-%d')\n",
    "    df.loc[19,'last_service_date']  = datetime.datetime.strptime('2016-06-30', '%Y-%m-%d')\n",
    "    df.loc[20,'last_service_date']  = datetime.datetime.strptime('2016-06-30', '%Y-%m-%d')\n",
    "    df.loc[21,'last_service_date']  = datetime.datetime.strptime('2016-06-30', '%Y-%m-%d')\n",
    "    df.loc[77,'last_service_date']  = datetime.datetime.strptime('2016-06-30', '%Y-%m-%d')\n",
    "    df.loc[100,'last_service_date']  = datetime.datetime.strptime('2016-06-30', '%Y-%m-%d')  # station 21 update, special index\n",
    "    \n",
    "\n",
    "    # FROM NOTES - Four of these stations have since been moved to either San Francisco or San Jose. (Stations 23, 24, 25 and 26 have become stations 88, 89, 90 and 91 respectively). Although these stations were promptly re-named, there was a delay in assigning them new station IDs. Full details:\n",
    "        # Cleaning Step \n",
    "\n",
    "\n",
    "    # FROM NOTES - On 7/5/16, Station 23, \"San Mateo County Center,\" was renamed to be \"5th S. at E. San Salvador St.” On 8/24/16, the station was reassigned to Station 88.\n",
    "        # Cleaning Step :  79\n",
    "    df.loc[16, 'last_service_date']  = datetime.datetime.strptime('2016-07-05', '%Y-%m-%d')\n",
    "    df.loc[79,'first_service_date']  = datetime.datetime.strptime('2016-07-05', '%Y-%m-%d')\n",
    "\n",
    "\n",
    "    # FROM NOTES - On 7/5/16, Station 24, \"Redwood City Public Library,\" was renamed to be \"S. Market St at Park Ave.” On 8/24/16, the station was reassigned to Station 89.\n",
    "        # Cleaning Step :  80\n",
    "    df.loc[18, 'last_service_date']  = datetime.datetime.strptime('2016-07-05', '%Y-%m-%d')\n",
    "    df.loc[80,'first_service_date']  = datetime.datetime.strptime('2016-07-05', '%Y-%m-%d')\n",
    "\n",
    "\n",
    "    # FROM NOTES - On 8/4/16, Station 25, \"Stanford in Redwood City,\" was renamed to be \"Cyril Magnin St at Ellis St.” On 8/24/16, the station was reassigned to Station 91.\n",
    "        # Cleaning Step :  82\n",
    "    df.loc[20, 'last_service_date']  = datetime.datetime.strptime('2016-08-04', '%Y-%m-%d')\n",
    "    df.loc[82,'first_service_date']  = datetime.datetime.strptime('2016-08-04', '%Y-%m-%d')\n",
    "\n",
    "\n",
    "    # FROM NOTES - On 8/4/16, Station 26, \"Kaiser Hospital,\" was renamed to be \"5th St at Folsom St.” On 8/24/16, the station was reassigned to Station 90.\n",
    "        # Cleaning Step :  81\n",
    "    df.loc[21, 'last_service_date']  = datetime.datetime.strptime('2016-08-04', '%Y-%m-%d')\n",
    "    df.loc[81,'first_service_date']  = datetime.datetime.strptime('2016-08-04', '%Y-%m-%d')\n",
    "    \n",
    "\n",
    "    # drop all rows in drop list and clean/reset index\n",
    "    df.drop(index_drop_list, inplace=True)\n",
    "    df.sort_values(['station_id', 'first_service_date'], inplace=True)\n",
    "    df.reset_index(inplace=True, drop=True)\n",
    "    \n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stations_df = clean_from_notes(stations_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stations_df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add some more Columns\n",
    "<p> Appending a few final columns of data from computations on given data.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# days in service is useful for popularity comparison as some stations were opened and closed on different dates\n",
    "stations_df['days_in_service'] = stations_df.apply(lambda row: days_in_service (row),axis=1)\n",
    "\n",
    "# final data type cleaning pass\n",
    "stations_df = clean_data_types(stations_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write Data to File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stations_df.to_csv('./clean_data/station_data_cleaned.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Preview EDA of Stations Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "docks_by_service_area = stations_df.groupby('landmark')['dock_count'].count().to_frame()\n",
    "plt.subplots(figsize=(15,6))\n",
    "ax = sns.barplot(x=docks_by_service_area.index, y='dock_count', data=docks_by_service_area)\n",
    "ax.set_title('Total Docks', size=TITLE_FONT_SIZE, weight='bold')\n",
    "ax.set_xlabel('Service Area', size=LABEL_FONT_SIZE)\n",
    "ax.set_xticklabels(sorted(pd.unique(stations_df.landmark)), rotation=0)\n",
    "ax.set_ylabel('Number of Docks', size=LABEL_FONT_SIZE)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots(figsize=(15,6))\n",
    "ax = sns.barplot(x='landmark', y='days_in_service', data=stations_df)\n",
    "ax.set_title('Days in Service', size=TITLE_FONT_SIZE, weight='bold')\n",
    "ax.set_xlabel('Service Area', size=LABEL_FONT_SIZE)\n",
    "ax.set_ylabel('Number of Docks', size=LABEL_FONT_SIZE)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots(figsize=(15,6))\n",
    "ax = sns.swarmplot(x='landmark', y='dock_count', data=stations_df, s=10)\n",
    "ax.set_title('Dock Per Station', size=TITLE_FONT_SIZE, weight='bold')\n",
    "ax.set_xlabel('Service Area', size=LABEL_FONT_SIZE)\n",
    "ax.set_ylabel('Number of Docks', size=LABEL_FONT_SIZE)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quick Reference to 'Special Stations'\n",
    "<p>Some stations were relocated, closed, or expanded during the program's recorded dataset being used in this analysis, this is a quick view to these notable stations</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stations that were relocated or expanded, thus there are duplicate 'station_id' values\n",
    "special_stations = stations_df[stations_df.duplicated(subset=['station_id'], keep=False)]\n",
    "special_stations.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Service was discontinued due to low ridership in Redwood City on September 1, 2016\n",
    "redwood_city = stations_df[stations_df.landmark == 'Redwood City']\n",
    "redwood_city.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
