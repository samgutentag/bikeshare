{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Investigation - Status Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "import datetime\n",
    "import math\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'math' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-17752fdf62a5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mchunk_counter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mnum_chunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mceil\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mchunksize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# import file in chunks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'math' is not defined"
     ]
    }
   ],
   "source": [
    "file = '../clean_data/status_data_15min_mean_cleaned.csv'\n",
    "\n",
    "chunks = []\n",
    "chunk_counter = 1\n",
    "chunksize = 10000\n",
    "num_chunks = math.ceil(sum(1 for row in open(file, 'r'))/chunksize)\n",
    "\n",
    "# import file in chunks\n",
    "for chunk in pd.read_csv(file, chunksize=chunksize, iterator=True, parse_dates=['time']):\n",
    "\n",
    "    # append chunk to chunks list\n",
    "    chunks.append(chunk)\n",
    "\n",
    "    if chunk_counter == 1 or chunk_counter % math.ceil(num_chunks/10) == 0 or chunk_counter == num_chunks:\n",
    "        print('\\t[%s] finished chunk %s of %s' % (datetime.datetime.now().time(), chunk_counter, num_chunks))\n",
    "    chunk_counter += 1\n",
    "    \n",
    "status_15min = pd.DataFrame()\n",
    "status_15min = pd.concat(chunks)\n",
    "\n",
    "status_15min.set_index('time', inplace=True)\n",
    "status_15min.head()\n",
    "\n",
    "status_15min.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# status_data = status_import.copy()\n",
    "# status_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# status_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean And Resample Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert time to datetime\n",
    "status_01_copy = status_01.copy()\n",
    "status_01_copy['time']   = pd.to_datetime(status_01_copy['time'],   format=\"%Y/%m/%d %H:%M:%S\")\n",
    "\n",
    "\n",
    "status_02_copy = status_02.copy()\n",
    "status_02_copy['time']   = pd.to_datetime(status_02_copy['time'],   format=\"%Y/%m/%d %H:%M:%S\")\n",
    "\n",
    "\n",
    "status_03_copy = status_03.copy()\n",
    "status_03_copy['time']   = pd.to_datetime(status_03_copy['time'],   format=\"%m/%d/%Y %H:%M:%S\")\n",
    "\n",
    "\n",
    "status_04_copy = status_04.copy()\n",
    "status_04_copy['time']   = pd.to_datetime(status_04_copy['time'],   format=\"%Y/%m/%d %H:%M:%S\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "status_02_copy.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "status_time_clean = pd.concat([status_01_copy, status_02_copy, status_03_copy, status_04_copy])\n",
    "status_time_clean.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# append total_docks column\n",
    "status_time_clean['total_docks'] = status_time_clean['bikes_available'] + status_time_clean['docks_available']\n",
    "status_time_clean.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "status_time_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set time column as index\n",
    "status_time_clean.set_index('time', inplace=True)\n",
    "\n",
    "status_data = status_time_clean.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> From Analysis of Trip Data, we can see that key commute hours for Subscribers are:\n",
    "-    Morning Commute Hours 07:00-11:00\n",
    "-    Evening Commute Hours 16:00-20:00\n",
    "\n",
    "> From Analysis of Trip Data, we can see that key Stations for Subscribers are:\n",
    "-    Morning Commute Stations \n",
    "    - top_am_commute_start_terms = [50, 54, 55, 61, 67, 69, 70, 73, 74, 77]\n",
    "    - top_am_commute_end_terms   = [51, 55, 60, 61, 63, 65, 69, 70, 74, 77]\n",
    ">\n",
    ">\n",
    "-    Evening Commute Stations \n",
    "    - top_pm_commute_start_terms = [55, 60, 61, 64, 65, 67, 69, 70, 74, 77]\n",
    "    - top_pm_commute_end_terms   = [39, 50, 55, 60, 61, 65, 69, 70, 74, 77]\n",
    ">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# prune only morning commute hours from subscribers [07:00 - 11:00]\n",
    "am_commute_start = datetime.datetime.strptime('07:00', '%H:%M').time()\n",
    "am_commute_end = datetime.datetime.strptime('11:00', '%H:%M').time()\n",
    "morning_commute_status = status_data.between_time(start_time=am_commute_start,\n",
    "                                                     end_time=am_commute_end,\n",
    "                                                     include_start=True,\n",
    "                                                     include_end=True)\n",
    "\n",
    "morning_commute_status.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# prune only evening commute hours from subscribers [16:00 - 20:00]\n",
    "pm_commute_start = datetime.datetime.strptime('16:00', '%H:%M').time()\n",
    "pm_commute_end = datetime.datetime.strptime('20:00', '%H:%M').time()\n",
    "evening_commute_status = status_data.between_time(start_time=pm_commute_start,\n",
    "                                                     end_time=pm_commute_end,\n",
    "                                                     include_start=True,\n",
    "                                                     include_end=True)\n",
    "\n",
    "evening_commute_status.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# prune only important stations for each commute period\n",
    "top_am_commute_start_terms = [50, 54, 55, 61, 67, 69, 70, 73, 74, 77]\n",
    "top_am_commute_end_terms = [51, 55, 60, 61, 63, 65, 69, 70, 74, 77]\n",
    "top_pm_commute_start_terms = [55, 60, 61, 64, 65, 67, 69, 70, 74, 77]\n",
    "top_pm_commute_end_terms = [39, 50, 55, 60, 61, 65, 69, 70, 74, 77]\n",
    "\n",
    "\n",
    "morning_commute_status_start = morning_commute_status[morning_commute_status.station_id.isin(top_am_commute_start_terms)].copy()\n",
    "morning_commute_status_end   = morning_commute_status[morning_commute_status.station_id.isin(top_am_commute_end_terms)].copy()\n",
    "evening_commute_status_start = evening_commute_status[evening_commute_status.station_id.isin(top_pm_commute_start_terms)].copy()\n",
    "evening_commute_status_end   = evening_commute_status[evening_commute_status.station_id.isin(top_pm_commute_end_terms)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "morning_commute_status_start.groupby(['station_id', morning_commute_status_start.index.hour])['docks_available'].plot(figsize=(12,6))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "morning_commute_status_start.groupby(['station_id', morning_commute_status_start.index.hour, morning_commute_status_start.index.minute]).mean()['docks_available'].plot(figsize=(12,6))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in pd.unique(morning_commute_status_start.station_id):\n",
    "    data = morning_commute_status_start[morning_commute_status_start.station_id == i]\n",
    "    data.groupby(['station_id', data.index.hour, data.index.minute]).mean()['bikes_available'].plot(figsize=(12,3))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "status_data.info()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in pd.unique(status_data.station_id):\n",
    "    data = status_data[status_data.station_id == i]\n",
    "    data.groupby(['station_id', data.index.hour, data.index.minute]).mean()['bikes_available'].plot(figsize=(12,3))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for i in pd.unique(status_data.station_id):\n",
    "#     data = status_data[status_data.station_id == i]\n",
    "status_data.groupby([status_data.index.hour, status_data.index.minute]).mean()['bikes_available'].plot(figsize=(12,3))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "ax = evening_commute_status.groupby([evening_commute_status.index.hour, evening_commute_status.index.minute]).mean()['bikes_available'].plot(figsize=(12,6))\n",
    "morning_commute_status.groupby([morning_commute_status.index.hour, morning_commute_status.index.minute]).mean()['bikes_available'].plot(ax=ax)\n",
    "plt.legend(['evening', 'morning'],loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "ax = evening_commute_status.groupby([evening_commute_status.index.hour, evening_commute_status.index.minute]).sum()['bikes_available'].plot(figsize=(12,6))\n",
    "morning_commute_status.groupby([morning_commute_status.index.hour, morning_commute_status.index.minute]).sum()['bikes_available'].plot(ax=ax)\n",
    "plt.legend(['evening', 'morning'],loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "status_73_data = status_data[status_data.station_id == 73]\n",
    "\n",
    "status_73_data.groupby([status_73_data.index.hour, status_73_data.index.minute]).max()['bikes_available'].plot(figsize=(12,6))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
