{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistical Analysis of Bay Area Bike Share Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> From our initial Visual Exploratory Data Analysis on the Bay Area BIke Share dataset, we inferred that the vast majority of the trips are taken by cummuters, who are subscribers.\n",
    ">\n",
    "> We will also be retaining from previous analysis that we only need concern ourselves with trips no more than 60 minutes in duration\n",
    ">\n",
    "> Predicting ridership appears pretty easy, commuters need to commute, and customers seem to be mostly starting or ending their trips at propular tourist destinations.\n",
    ">\n",
    "> 1 What factors, if any, have an impact on the duration of rides for customers and subscribers?\n",
    "> \n",
    "> 2 What factors, if any, have an impact on the distance customers' and subscribers' trips cover?\n",
    "- gps route data is not collected by Bay Area Bike Share, so we will simply be estimating the distance travelled by calulating the distance between the start and end terminal of each trip\n",
    "- trips that start and end at the same terminal, or \"round trips\", are defaulted to a distance of 0.0 km.\n",
    ">\n",
    "> 3 Are the number of trips taken by subscribers in morning commute hours coorelated to the number of trips taken by subscribers in evening commute hours?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from glob import glob\n",
    "from geopy.distance import vincenty\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Trip Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Trip Data...\n",
      "\tFinished file! (1 of 4)\n",
      "\tFinished file! (2 of 4)\n",
      "\tFinished file! (3 of 4)\n",
      "\tFinished file! (4 of 4)\n",
      "Data Loaded Successfully!\n"
     ]
    }
   ],
   "source": [
    "print('Loading Trip Data...')\n",
    "\n",
    "try:\n",
    "    file_path_slug = '../../datasets/bayareabikeshare/*_trip_data.csv'\n",
    "    file_list = glob(file_path_slug)\n",
    "\n",
    "    trip_import = pd.DataFrame()\n",
    "    \n",
    "    counter = 1\n",
    "    chunks = []\n",
    "    \n",
    "    for file in file_list:\n",
    "        for chunk in pd.read_csv(file, chunksize=10000, iterator=True):\n",
    "            chunk = chunk.set_index('Trip ID')\n",
    "            chunk.columns = ['Duration', 'Start Date', 'Start Station', 'Start Terminal', 'End Date', \n",
    "                             'End Station', 'End Terminal', 'Bike #', 'Subscriber Type', 'Zip Code']\n",
    "            chunks.append(chunk)\n",
    "        print('\\tFinished file! (%d of %d)' % (counter, len(file_list)))\n",
    "        counter += 1\n",
    "\n",
    "    trip_import = pd.concat(chunks)\n",
    "    print('Data Loaded Successfully!')\n",
    "\n",
    "except:\n",
    "    print('oops... something went wrong importing the data :(')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trip_data = trip_import.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Weather Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Weather Data...\n",
      "\tfinished file! (1 of 4)\n",
      "\tfinished file! (2 of 4)\n",
      "\tfinished file! (3 of 4)\n",
      "\tfinished file! (4 of 4)\n",
      "Data Loaded Successfully!\n"
     ]
    }
   ],
   "source": [
    "print('Loading Weather Data...')\n",
    "\n",
    "try:\n",
    "    file_path_slug = '../../datasets/bayareabikeshare/*_weather_data.csv'\n",
    "    file_list = glob(file_path_slug)\n",
    "\n",
    "    weather_import = pd.DataFrame()\n",
    "\n",
    "    counter = 1\n",
    "    chunks = []\n",
    "\n",
    "    for file in file_list:\n",
    "        for chunk in pd.read_csv(file, chunksize=10000, iterator=True):\n",
    "            chunk.columns = ['Date', 'Max_Temperature_F', 'Mean_Temperature_F', 'Min_TemperatureF', 'Max_Dew_Point_F', \n",
    "                             'MeanDew_Point_F', 'Min_Dewpoint_F', 'Max_Humidity', 'Mean_Humidity', 'Min_Humidity', \n",
    "                             'Max_Sea_Level_Pressure_In', 'Mean_Sea_Level_Pressure_In', 'Min_Sea_Level_Pressure_In', \n",
    "                             'Max_Visibility_Miles', 'Mean_Visibility_Miles', 'Min_Visibility_Miles', \n",
    "                             'Max_Wind_Speed_MPH', 'Mean_Wind_Speed_MPH', 'Max_Gust_Speed_MPH', 'Precipitation_In', \n",
    "                             'Cloud_Cover', 'Events', 'Wind_Dir_Degrees', 'zip']\n",
    "            chunks.append(chunk)\n",
    "        print('\\tfinished file! (%d of %d)'% (counter, len(file_list)))\n",
    "        counter += 1\n",
    "\n",
    "    weather_import = pd.concat(chunks)\n",
    "    print('Data Loaded Successfully!')\n",
    "except:\n",
    "    print('oops... something went wrong loading the data :()')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weather_data = weather_import.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Station Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Station Data...\n",
      "\tFinished file! (1 of 4)\n",
      "\tFinished file! (2 of 4)\n",
      "\tFinished file! (3 of 4)\n",
      "\tFinished file! (4 of 4)\n",
      "Data Loaded Successfully!\n"
     ]
    }
   ],
   "source": [
    "print('Loading Station Data...')\n",
    "\n",
    "try:\n",
    "    file_path_slug = '../../datasets/bayareabikeshare/*_station_data.csv'\n",
    "    file_list = glob(file_path_slug)\n",
    "\n",
    "    station_import = pd.DataFrame()\n",
    "\n",
    "    counter = 1\n",
    "    chunks = []\n",
    "\n",
    "    for file in file_list:\n",
    "        for chunk in pd.read_csv(file, chunksize=10000, iterator=True):\n",
    "            chunk.columns = ['station_id', 'name', 'lat', 'long', 'dockcount', 'landmark', 'installation']            \n",
    "            chunks.append(chunk)\n",
    "        print('\\tFinished file! (%d of %d)' % (counter, len(file_list)))\n",
    "        counter += 1\n",
    "\n",
    "    station_import = pd.concat(chunks)\n",
    "    print('Data Loaded Successfully!')\n",
    "except:\n",
    "    print('oops... something went wrong importing the data :(')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "station_data = station_import.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trip Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# our data set show duration in seconds, here are some handy conversions\n",
    "second = 1\n",
    "minute = second * 60\n",
    "hour = minute * 60\n",
    "\n",
    "# zipcodes are all over the place, only keep corrected 5 digit zipcodes, and replace all others with NaNs\n",
    "def clean_zipcode(item):\n",
    "    if len(item) != 5:\n",
    "        # split on '-'\n",
    "        try:\n",
    "            result = item.split('-')[0]\n",
    "        except:\n",
    "            result = item\n",
    "        # split on '.'\n",
    "        try:\n",
    "            result = item.split('.')[0]\n",
    "        except:\n",
    "            result = item\n",
    "        # if len of item is less than 5, return 'NaN'\n",
    "        if len(result) < 5:\n",
    "            result = 'NaN'\n",
    "        else:\n",
    "            # if len result is greater than 5, take at most, first 5 digits\n",
    "            result = result[:5]\n",
    "    else:\n",
    "        result = item\n",
    "    # make sure result is all digits\n",
    "    if result.isdigit():\n",
    "        return result\n",
    "    else:\n",
    "        return 'NaN'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trip Data Cleanup Started...\n",
      "\tcleaning column names\n",
      "\tsubsetting to useful columns\n",
      "\tcreating a duration_minutes column\n",
      "\tconverting end and start dates to datetime objects\n",
      "\tcreating trip_date and trip_dow columns\n",
      "\tcreating start_hour and end_hour columns\n",
      "\tcleaning zipcodes\n",
      "cleaning up data types\n",
      "pruning data to trips no more than 60 minutes long...\n",
      "\tpruned data set 'trip_data' consists of 955557 entries\n",
      "Trip Data Cleanup complete\n"
     ]
    }
   ],
   "source": [
    "print('Trip Data Cleanup Started...')\n",
    "\n",
    "# cleanup column names\n",
    "print('\\tcleaning column names')\n",
    "new_cols = []\n",
    "for col in trip_data.columns:\n",
    "    new_cols.append(col.replace(' ', '_').lower())\n",
    "trip_data.columns = new_cols\n",
    "\n",
    "# extract columns we want to keep\n",
    "print('\\tsubsetting to useful columns')\n",
    "important_cols = ['duration', 'start_date', 'start_terminal', 'end_date', 'end_terminal', 'bike_#', 'subscriber_type', 'zip_code']\n",
    "trip_data = trip_data[important_cols]\n",
    "\n",
    "# create duration minutes column\n",
    "print('\\tcreating a duration_minutes column')\n",
    "trip_data['duration_minutes'] = trip_data['duration'] / 60.0\n",
    "\n",
    "# convert end and start dates to datetime objects\n",
    "print('\\tconverting end and start dates to datetime objects')\n",
    "trip_data['start_date'] = pd.to_datetime(trip_data['start_date'], format=\"%m/%d/%Y %H:%M\")\n",
    "trip_data['end_date']   = pd.to_datetime(trip_data['end_date'],   format=\"%m/%d/%Y %H:%M\")\n",
    "\n",
    "# create a start and end hour trip column\n",
    "print('\\tcreating trip_date and trip_dow columns')\n",
    "trip_data['trip_date']  = trip_data['start_date'].dt.date\n",
    "trip_data['trip_dow']  = trip_data['start_date'].dt.weekday\n",
    "trip_data['trip_day']  = trip_data['start_date'].dt.weekday_name\n",
    "\n",
    "print('\\tcreating start_hour and end_hour columns')\n",
    "trip_data['start_hour'] = trip_data['start_date'].dt.hour\n",
    "trip_data['end_hour']   = trip_data['end_date'].dt.hour\n",
    "\n",
    "# convert and clean zipcodes\n",
    "print('\\tcleaning zipcodes')\n",
    "trip_data['zip_code'] = trip_data['zip_code'].astype(str)\n",
    "trip_data.zip_code = trip_data.zip_code.apply(clean_zipcode)\n",
    "trip_data['zip_code'] = pd.to_numeric(trip_data['zip_code'], errors='coerce')\n",
    "\n",
    "# clean up data types\n",
    "print('cleaning up data types')\n",
    "\n",
    "trip_data['duration']         = trip_data['duration'].astype('float')\n",
    "trip_data['start_terminal']   = trip_data['start_terminal'].astype('category')\n",
    "trip_data['end_terminal']     = trip_data['end_terminal'].astype('category')\n",
    "trip_data['bike_#']           = trip_data['bike_#'].astype('int')\n",
    "trip_data['subscriber_type']  = trip_data['subscriber_type'].astype('category')\n",
    "trip_data['zip_code']         = trip_data['zip_code'].astype('str')\n",
    "trip_data['duration_minutes'] = trip_data['duration_minutes'].astype('float')\n",
    "trip_data['trip_dow']         = trip_data['trip_dow'].astype('category')\n",
    "trip_data['trip_day']         = trip_data['trip_day'].astype('category')\n",
    "\n",
    "# prune data to exclude trips longer than 60 minutes\n",
    "print('pruning data to trips no more than 60 minutes long...')\n",
    "trip_data = trip_data[trip_data['duration_minutes'] <= 60]\n",
    "\n",
    "# Cleanup\n",
    "trip_data.sort_index(inplace=True)\n",
    "print('\\tpruned data set \\'trip_data\\' consists of %i entries' % len(trip_data.index))\n",
    "\n",
    "print('Trip Data Cleanup complete')\n",
    "trip_clean = trip_data.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weather Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weather Data Cleanup Started...\n",
      "\tcleaning column names\n",
      "\tconverting dates to datetime objects\n",
      "\tsubsetting to useful columns\n",
      "Weather Data Cleanup complete\n"
     ]
    }
   ],
   "source": [
    "print('Weather Data Cleanup Started...')\n",
    "\n",
    "# cleanup column names\n",
    "print('\\tcleaning column names')\n",
    "new_cols = []\n",
    "for col in weather_data.columns:\n",
    "    new_cols.append(col.replace(' ', '_').lower())\n",
    "weather_data.columns = new_cols\n",
    "\n",
    "# convert end and start dates to datetime objects\n",
    "print('\\tconverting dates to datetime objects')\n",
    "weather_data['date'] = pd.to_datetime(weather_data['date'], format=\"%m/%d/%Y\")\n",
    "\n",
    "# extract columns we want to keep\n",
    "print('\\tsubsetting to useful columns')\n",
    "important_cols = ['date', 'max_temperature_f', 'mean_temperature_f', 'min_temperaturef',\n",
    "                  'max_wind_speed_mph', 'mean_wind_speed_mph', 'max_gust_speed_mph',\n",
    "                  'precipitation_in', 'cloud_cover', 'events', 'zip']\n",
    "weather_data = weather_data[important_cols]\n",
    "\n",
    "# correct min_temperaturef column name to min_temperature_f\n",
    "weather_data.rename(columns={'min_temperaturef': 'min_temperature_f'}, inplace=True)\n",
    "\n",
    "# cleanup and set date as index\n",
    "weather_data.set_index('date', inplace=True)\n",
    "weather_data.sort_index(inplace=True)\n",
    "\n",
    "# cleanup precipitation data to be all float values\n",
    "weather_data['precipitation_in'] = pd.to_numeric(weather_data['precipitation_in'], errors='coerce')\n",
    "\n",
    "# we only want San Francisco Weather information, zipcode 94107\n",
    "weather_data = weather_data[weather_data.zip == 94107]\n",
    "\n",
    "print('Weather Data Cleanup complete')\n",
    "weather_clean = weather_data.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Station Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def label_zip(row):\n",
    "    if row['landmark'] == 'San Francisco':\n",
    "       return '94107'\n",
    "    if row['landmark'] == 'Redwood City':\n",
    "        return '94063'\n",
    "    if row['landmark'] == 'Palo Alto':\n",
    "        return '94301'\n",
    "    if row['landmark'] == 'Mountain View':\n",
    "        return '94041'\n",
    "    if row['landmark'] == 'San Jose':\n",
    "        return '95113'\n",
    "    return '99999'\n",
    "\n",
    "def make_lat_long(row):\n",
    "    lat = row['lat']\n",
    "    long = row['long']\n",
    "    return (lat, long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "remove dulplicates\n",
      "set datatype for each column\n",
      "correcting index\n",
      "Cleaning complete!\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 77 entries, 2 to 91\n",
      "Data columns (total 8 columns):\n",
      "name            77 non-null object\n",
      "lat             77 non-null float64\n",
      "long            77 non-null float64\n",
      "dockcount       77 non-null float64\n",
      "landmark        77 non-null category\n",
      "installation    77 non-null object\n",
      "zip_code        77 non-null object\n",
      "lat_long        77 non-null object\n",
      "dtypes: category(1), float64(3), object(4)\n",
      "memory usage: 5.1+ KB\n"
     ]
    }
   ],
   "source": [
    "station_data = station_import.copy()\n",
    "\n",
    "# remove dulplicates\n",
    "print('remove dulplicates')\n",
    "station_data.drop_duplicates(keep='first', inplace=True)\n",
    "station_data.dropna(how='all', inplace=True)\n",
    "\n",
    "# set datatype for each column\n",
    "print('set datatype for each column')\n",
    "station_data['station_id']   = station_data['station_id'].astype('int')\n",
    "station_data['name']         = station_data['name'].astype('str')\n",
    "station_data['lat']          = station_data['lat'].astype('float')\n",
    "station_data['long']         = station_data['long'].astype('float')\n",
    "station_data['landmark']     = station_data['landmark'].astype('category')\n",
    "\n",
    "# add a zipcode column for later comparison with weather data\n",
    "station_data['zip_code'] = station_data.apply(lambda row: label_zip (row),axis=1)\n",
    "# station_data['zip_code'] = station_data['landmark'].astype('str')\n",
    "\n",
    "# create lat,lon tuple column\n",
    "station_data['lat_long'] = station_data.apply(lambda row: make_lat_long (row),axis=1)\n",
    "\n",
    "# reindex to remove some extra duplicate\n",
    "print('correcting index')\n",
    "station_data.reset_index(inplace=True)\n",
    "station_data.drop_duplicates(['station_id', 'installation'], keep='first', inplace=True)\n",
    "station_data.set_index('station_id', inplace=True)\n",
    "station_data.sort_index(inplace=True)\n",
    "del station_data['index']\n",
    "\n",
    "station_clean = station_data.copy()\n",
    "print('Cleaning complete!')\n",
    "station_clean.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appending Distance Data to Trips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def route_distance(row):\n",
    "    \n",
    "    # round trips are defaulting to zero km\n",
    "    if row['start_terminal'] == row['end_terminal']:\n",
    "        dist = 0.0\n",
    "    else:\n",
    "        # lookup start_station id coords\n",
    "        start_gps = station_clean.loc[row['start_terminal']]['lat_long']\n",
    "        end_gps = station_clean.loc[row['end_terminal']]['lat_long']\n",
    "\n",
    "        if isinstance(start_gps, pd.core.series.Series):\n",
    "            start_gps = start_gps.iloc[-1]\n",
    "        if isinstance(end_gps, pd.core.series.Series):\n",
    "            end_gps = end_gps.iloc[-1]\n",
    "        # sloppy lookup, uses most recent station coordinates\n",
    "        # does not account for stations that are relocated over time correctly\n",
    "        try:\n",
    "            dist = str(vincenty(start_gps, end_gps))\n",
    "            dist = float(dist.split(' ')[0])\n",
    "        except:\n",
    "            dist = 'NaN'  \n",
    "    return dist\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-38da2281c990>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrip_clean\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'distance_km'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrip_clean\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mroute_distance\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda/envs/springboard/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, axis, broadcast, raw, reduce, args, **kwds)\u001b[0m\n\u001b[1;32m   4260\u001b[0m                         \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4261\u001b[0m                         \u001b[0mreduce\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4262\u001b[0;31m                         ignore_failures=ignore_failures)\n\u001b[0m\u001b[1;32m   4263\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4264\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply_broadcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/springboard/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_apply_standard\u001b[0;34m(self, func, axis, ignore_failures, reduce)\u001b[0m\n\u001b[1;32m   4356\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4357\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseries_gen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4358\u001b[0;31m                     \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4359\u001b[0m                     \u001b[0mkeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4360\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-38da2281c990>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(row)\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrip_clean\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'distance_km'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrip_clean\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mroute_distance\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-13-e729bd8c480b>\u001b[0m in \u001b[0;36mroute_distance\u001b[0;34m(row)\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;31m# lookup start_station id coords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mstart_gps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstation_clean\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'start_terminal'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lat_long'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mend_gps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstation_clean\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'end_terminal'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lat_long'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_gps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseries\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/springboard/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1326\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m             \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1328\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/springboard/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1550\u001b[0m         \u001b[0;31m# fall thru to straight lookup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1551\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_has_valid_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1552\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/springboard/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_label\u001b[0;34m(self, label, axis)\u001b[0m\n\u001b[1;32m    134\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mIndexingError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'no slices here, handle elsewhere'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_xs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/springboard/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mxs\u001b[0;34m(self, key, axis, level, drop_level)\u001b[0m\n\u001b[1;32m   2043\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2044\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2045\u001b[0;31m             \u001b[0mnew_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfast_xs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2046\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2047\u001b[0m             \u001b[0;31m# may need to box a datelike-scalar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/springboard/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mfast_xs\u001b[0;34m(self, loc)\u001b[0m\n\u001b[1;32m   3534\u001b[0m         \u001b[0msingle\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3535\u001b[0m         \"\"\"\n\u001b[0;32m-> 3536\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3537\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mslice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3538\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trip_clean['distance_km'] = trip_clean.apply(lambda row: route_distance (row),axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting up Rainy and Dry Days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# split up rainy days and dry days\n",
    "rainy_days = weather_clean[ weather_clean['precipitation_in'] > 0.0].reset_index()\n",
    "dry_days =   weather_clean[-weather_clean['precipitation_in'] > 0.0].reset_index()\n",
    "\n",
    "# All trips\n",
    "rainy_trips = trip_clean[ trip_clean['start_date'].dt.date.isin(rainy_days['date'].dt.date)]\n",
    "dry_trips   = trip_clean[-trip_clean['start_date'].dt.date.isin(rainy_days['date'].dt.date)]\n",
    "\n",
    "# Customer Trips\n",
    "customer_rainy_trips = rainy_trips[rainy_trips.subscriber_type == 'Customer']\n",
    "customer_dry_trips = dry_trips[dry_trips.subscriber_type == 'Customer']\n",
    "\n",
    "# Subscriber Trips\n",
    "subscriber_rainy_trips = rainy_trips[rainy_trips.subscriber_type == 'Subscriber']\n",
    "subscriber_dry_trips = dry_trips[dry_trips.subscriber_type == 'Subscriber']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_stats(data1, data2):\n",
    "\n",
    "    # means\n",
    "    data1_mean = data1.mean()\n",
    "    data2_mean = data2.mean()\n",
    "    diff_mean = data1_mean - data2_mean\n",
    "    print('Diff of means:\\t\\t', diff_mean)\n",
    "\n",
    "    # calculate t statistic and p value with scipy\n",
    "    t, p = stats.ttest_ind(data1, data2)\n",
    "    print('T Test')\n",
    "    print('\\tt statistic:\\t\\t', t)\n",
    "    print('\\tp value:\\t\\t', p)\n",
    "    print('')\n",
    "    u, p2 = stats.mannwhitneyu(data1, data2)\n",
    "    print('MannWhitneyU Test')\n",
    "    print('\\tu statistic:\\t\\t', u)\n",
    "    print('\\tp value:\\t\\t', p2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Does Rain Affect Trips Duration of Customers or of Subscribers?\n",
    "\n",
    "> A <b>Two Sample T Test</b> is appropriate for this problem as we are trying to see a difference between two sample means\n",
    "- Mean ride duration on rainy days vs mean ride duration on dry days\n",
    ">\n",
    ">\n",
    "> ##### Customer Trips\n",
    "- $HC$o : Customer Mean Trip Duration on Rainy Days = Customer Mean Trip Duration on Dry Days\n",
    "- $HC$a : Customer Mean Trip Duration on Rainy Days ≠ Customer Mean Trip Duration on Dry Days\n",
    ">\n",
    "> ##### Subscriber Trips\n",
    "- $HS$o : Subscriber Mean Trip Duration on Rainy Days = Subscriber Mean Trip Duration on Dry Days\n",
    "- $HS$a : Subscriber Mean Trip Duration on Rainy Days ≠ Subscriber Mean Trip Duration on Dry Days"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Results\n",
    "\n",
    "> #### Customer Trips\n",
    "> Mean trip durations on rainy days are equal mean trip durations on dry days\n",
    "- T Statistic <b>-1.7365</b> \n",
    "- P Value <b>0.08248</b> which is above the 0.05 threshhold thus we <b>can not reject</b> the $HC$o\n",
    "- Trips are <b>0.2751 minutes</b> shorter on rainy days than on dry days\n",
    "\n",
    "> #### Subscriber Trips\n",
    "> Mean trip durations on rainy days are not equal to mean trip durations on dry days\n",
    "- T Statistic <b>-11.5929</b> \n",
    "- P Value <b>4.4994e-31</b> which is well below the 0.05 threshhold thus we <b>reject</b> the $HS$o\n",
    "- Trips are <b>0.2209 minutes</b> shorter on rainy days than on dry days\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Customer Trips Only\n",
    "customer_rainy_data = customer_rainy_trips.duration_minutes\n",
    "customer_dry_data = customer_dry_trips.duration_minutes\n",
    "\n",
    "# Subscriber Trips Only\n",
    "subscriber_rainy_data = subscriber_rainy_trips.duration_minutes\n",
    "subscriber_dry_data = subscriber_dry_trips.duration_minutes\n",
    "\n",
    "print('-' * 40)\n",
    "print('Customer Trips')\n",
    "calculate_stats(customer_rainy_data, customer_dry_data)\n",
    "print()\n",
    "print('-' * 40)\n",
    "print('Subscriber Trips')\n",
    "calculate_stats(subscriber_rainy_data, subscriber_dry_data)\n",
    "print()\n",
    "print('-' * 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Does Rain Affect Trips Distance of Customers or of Subscribers?\n",
    "\n",
    "> A <b>Two Sample T Test</b> is appropriate for this problem as we are trying to see a difference between two sample means\n",
    "- Mean ride duration on rainy days vs mean ride duration on dry days\n",
    ">\n",
    ">\n",
    "> ##### Customer Trips\n",
    "- $HC$o : Customer Mean Trip Distance on Rainy Days = Customer Mean Trip Distance on Dry Days\n",
    "- $HC$a : Customer Mean Trip Distance on Rainy Days ≠ Customer Mean Trip Distance on Dry Days\n",
    ">\n",
    "> ##### Subscriber Trips\n",
    "- $HS$o : Subscriber Mean Trip Distance on Rainy Days = Subscriber Mean Trip Distance on Dry Days\n",
    "- $HS$a : Subscriber Mean Trip Distance on Rainy Days ≠ Subscriber Mean Trip Distance on Dry Days"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Results\n",
    "\n",
    "> #### Customer Trips\n",
    "> Mean trip durations on rainy days are equal mean trip durations on dry days\n",
    "- T Statistic <b>-0.5084</b> \n",
    "- P Value <b>0.61114</b> which is above the 0.05 threshhold thus we <b>can not reject</b> the $HC$o\n",
    "- Trips are <b>0.00575 km</b> shorter on rainy days than on dry days\n",
    "\n",
    "> #### Subscriber Trips\n",
    "> Mean trip durations on rainy days are not equal to mean trip durations on dry days\n",
    "- T Statistic <b>-7.6683</b> \n",
    "- P Value <b>1.7454e-14</b> which is well below the 0.05 threshhold thus we <b>reject</b> the $HS$o\n",
    "- Trips are <b>0.0208 km</b> shorter on rainy days than on dry days"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Customer Trips Only\n",
    "customer_rainy_data = customer_rainy_trips.distance_km\n",
    "customer_dry_data = customer_dry_trips.distance_km\n",
    "\n",
    "# Subscriber Trips Only\n",
    "subscriber_rainy_data = subscriber_rainy_trips.distance_km\n",
    "subscriber_dry_data = subscriber_dry_trips.distance_km\n",
    "\n",
    "print('-' * 40)\n",
    "print('Customer Trips')\n",
    "calculate_stats(customer_rainy_data, customer_dry_data)\n",
    "print()\n",
    "print('-' * 40)\n",
    "print('Subscriber Trips')\n",
    "calculate_stats(subscriber_rainy_data, subscriber_dry_data)\n",
    "print()\n",
    "print('-' * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Customer Trips\n",
    "customer_trips = trip_clean[trip_clean.subscriber_type == 'Customer']\n",
    "\n",
    "# Subscriber Trips\n",
    "subscriber_trips = trip_clean[trip_clean.subscriber_type == 'Subscriber']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### compare morning and evening commute hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def commute_timer(row, start_time):\n",
    "    orig = row.start_date.to_pydatetime()\n",
    "    orig_time = orig.time()\n",
    "    \n",
    "    a = datetime.timedelta(hours=orig_time.hour, minutes=orig_time.minute, seconds=orig_time.second)\n",
    "    b = datetime.timedelta(hours=start_time.hour, minutes=start_time.minute, seconds=start_time.second)\n",
    "\n",
    "    result = a - b\n",
    "    \n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# prune only morning commute hours from subscribers [07:00 - 11:00]\n",
    "am_commute_start = datetime.datetime.strptime('07:00', '%H:%M').time()\n",
    "am_commute_end = datetime.datetime.strptime('11:00', '%H:%M').time()\n",
    "morning_commutes = subscriber_trips[subscriber_trips.start_date.dt.time >= am_commute_start]\n",
    "morning_commutes = morning_commutes[morning_commutes.start_date.dt.time < am_commute_end]\n",
    "\n",
    "# prune only evening commute hours from subscribers [16:00 - 20:00]\n",
    "pm_commute_start = datetime.datetime.strptime('16:00', '%H:%M').time()\n",
    "pm_commute_end = datetime.datetime.strptime('20:00', '%H:%M').time()\n",
    "evening_commutes = subscriber_trips[subscriber_trips.start_date.dt.time >= pm_commute_start]\n",
    "evening_commutes = evening_commutes[evening_commutes.start_date.dt.time < pm_commute_end]\n",
    "\n",
    "# morning_commutes['time_adjust'] = morning_commutes.start_date.dt.time - am_commute_start\n",
    "morning_commutes['time_adj'] = morning_commutes.apply(lambda row: commute_timer(row, am_commute_start),axis=1)\n",
    "evening_commutes['time_adj'] = evening_commutes.apply(lambda row: commute_timer(row, pm_commute_start),axis=1)\n",
    "\n",
    "# fix time_adj type\n",
    "morning_commutes.time_adj = morning_commutes.time_adj.astype('timedelta64[m]')\n",
    "evening_commutes.time_adj = evening_commutes.time_adj.astype('timedelta64[m]')\n",
    "\n",
    "print('morning_commutes:\\t', len(morning_commutes))\n",
    "print('evening_commutes:\\t', len(evening_commutes))\n",
    "\n",
    "# plot the data\n",
    "plt.subplots(figsize=(12,6))\n",
    "\n",
    "ax = sns.distplot(morning_commutes.time_adj, color='b', label='morning')\n",
    "sns.distplot(evening_commutes.time_adj, color='y', label='evening', ax=ax)\n",
    "\n",
    "ax.set(xlabel='start hour')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# calculate some statistics\n",
    "am_commuters = morning_commutes.groupby('time_adj')['start_terminal'].count()\n",
    "pm_commuters = evening_commutes.groupby('time_adj')['start_terminal'].count()\n",
    "\n",
    "print('-' * 40)\n",
    "print('Commuter Trips')\n",
    "calculate_stats(am_commuters, pm_commuters)\n",
    "print()\n",
    "print('-' * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "commute_hours = pd.DataFrame()\n",
    "commute_hours['morning'] = am_commuters\n",
    "commute_hours['evening'] = pm_commuters\n",
    "\n",
    "sns.jointplot(x='morning', y='evening', data=commute_hours, kind='reg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split morning and evening - Subscribers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trip_time_adj(row):\n",
    "    orig = row.start_date.to_pydatetime()\n",
    "    orig_time = orig.time()\n",
    "    \n",
    "    noon = datetime.datetime.strptime('12:00', '%H:%M').time()\n",
    "    midnight = datetime.datetime.strptime('00:00', '%H:%M').time()\n",
    "    \n",
    "    # this is horribly inneficient, but it does work\n",
    "    _orig = datetime.timedelta(hours=orig_time.hour, minutes=orig_time.minute, seconds=orig_time.second)\n",
    "    _noon = datetime.timedelta(hours=noon.hour, minutes=noon.minute, seconds=noon.second)\n",
    "    _midnight = datetime.timedelta(hours=midnight.hour, minutes=midnight.minute, seconds=midnight.second)\n",
    "    \n",
    "    if _orig > _noon:\n",
    "        result = _orig - _noon\n",
    "    else:\n",
    "        result = _midnight + _orig       \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "noon = datetime.datetime.strptime('12:00', '%H:%M').time()\n",
    "\n",
    "# split subscriber trips into morning and evening trip times [00:00 - 11:59], [12:00, 23:59]\n",
    "morning_trips = subscriber_trips[subscriber_trips.start_date.dt.time < noon].copy()\n",
    "afternoon_trips = subscriber_trips[subscriber_trips.start_date.dt.time >= noon].copy()\n",
    "\n",
    "# create adjusted time for comparison, reduced to minutes after midnight and minutes after noon\n",
    "morning_trips['time_adj'] = morning_trips.apply(lambda row: trip_time_adj(row),axis=1)\n",
    "afternoon_trips['time_adj'] = afternoon_trips.apply(lambda row: trip_time_adj(row),axis=1)\n",
    "\n",
    "# fix time_adj type\n",
    "morning_trips.time_adj = morning_trips.time_adj.astype('timedelta64[m]')\n",
    "afternoon_trips.time_adj = afternoon_trips.time_adj.astype('timedelta64[m]')\n",
    "\n",
    "print('morning_trips:\\t\\t', len(morning_trips))\n",
    "print('afternoon_trips:\\t', len(afternoon_trips))\n",
    "\n",
    "# plot the data\n",
    "plt.subplots(figsize=(12,6))\n",
    "\n",
    "sns.distplot(morning_trips.time_adj, color='b', label='morning')\n",
    "sns.distplot(afternoon_trips.time_adj, color='y', label='evening')\n",
    "\n",
    "ax.set(xlabel='start hour')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# calculate some statistics!\n",
    "am_trips = morning_trips.groupby('time_adj')['start_terminal'].count()\n",
    "pm_trips = afternoon_trips.groupby('time_adj')['start_terminal'].count()\n",
    "\n",
    "print('-' * 40)\n",
    "print('Commuter Trips')\n",
    "calculate_stats(am_trips, pm_trips)\n",
    "print()\n",
    "print('-' * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.subplots(figsize=(12,6))\n",
    "sns.distplot(trip_clean[trip_clean.subscriber_type == 'Customer'].start_date.dt.hour, color='r', label='Customers')\n",
    "ax.set(xlabel='start hour')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split morning and evening - Customers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "noon = datetime.datetime.strptime('12:00', '%H:%M').time()\n",
    "\n",
    "# prune only morning commute hours from customers [07:00 - 11:00]\n",
    "am_trip_start = datetime.datetime.strptime('08:00', '%H:%M').time()\n",
    "am_trip_end   = datetime.datetime.strptime('14:00', '%H:%M').time()\n",
    "\n",
    "morning_trips = customer_trips[customer_trips.start_date.dt.time >= am_commute_start].copy()\n",
    "morning_trips = morning_trips[morning_trips.start_date.dt.time < am_commute_end].copy()\n",
    "\n",
    "# prune only evening commute hours from customers [15:00 - 20:00]\n",
    "pm_trip_start = datetime.datetime.strptime('15:00', '%H:%M').time()\n",
    "pm_trip_end   = datetime.datetime.strptime('20:00', '%H:%M').time()\n",
    "\n",
    "evening_trips = customer_trips[customer_trips.start_date.dt.time >= pm_commute_start].copy()\n",
    "evening_trips = evening_trips[evening_trips.start_date.dt.time < pm_commute_end].copy()\n",
    "\n",
    "# create adjusted time for comparison, reduced to minutes after midnight and minutes after noon\n",
    "morning_trips['time_adj'] = morning_trips.apply(lambda row: commute_timer(row, am_trip_start),axis=1)\n",
    "evening_trips['time_adj'] = evening_trips.apply(lambda row: commute_timer(row, pm_trip_start),axis=1)\n",
    "\n",
    "# fix time_adj type\n",
    "morning_trips.time_adj = morning_trips.time_adj.astype('timedelta64[m]')\n",
    "evening_trips.time_adj = evening_trips.time_adj.astype('timedelta64[m]')\n",
    "\n",
    "print('morning_trips:\\t', len(morning_trips))\n",
    "print('evening_trips:\\t', len(evening_trips))\n",
    "\n",
    "# plot the data\n",
    "plt.subplots(figsize=(12,6))\n",
    "\n",
    "sns.distplot(morning_trips.time_adj, color='b', label='morning')\n",
    "sns.distplot(evening_trips.time_adj, color='y', label='evening')\n",
    "\n",
    "ax.set(xlabel='start hour')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# calculate some statistics!\n",
    "am_trips = morning_trips.groupby('time_adj')['start_terminal'].count()\n",
    "pm_trips = evening_trips.groupby('time_adj')['start_terminal'].count()\n",
    "\n",
    "print('-' * 40)\n",
    "print('Commuter Trips')\n",
    "calculate_stats(am_trips, pm_trips)\n",
    "print()\n",
    "print('-' * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
