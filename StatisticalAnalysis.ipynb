{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistical Analysis of Bay Area Bike Share Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> From our initial Visual Exploratory Data Analysis on the Bay Area BIke Share dataset, we inferred that the vast majority of the trips are taken by cummuters, who are subscribers.\n",
    ">\n",
    "> We will also be retaining from previous analysis that we only need concern ourselves with trips no more than 60 minutes in duration\n",
    ">\n",
    "> Predicting ridership appears pretty easy, commuters need to commute, and customers seem to be mostly starting or ending their trips at propular tourist destinations.\n",
    ">\n",
    "> <b>1</b> Are Customer or Subscriber trip counts affected by Rain?\n",
    "> \n",
    "> <b>2</b> Are Customer or Subscriber trip counts affected by Hot or Cold Temperatures?\n",
    ">\n",
    "> <b>3</b> Are the number of trips taken by subscribers in morning commute hours coorelated to the number of trips taken by subscribers in evening commute hours?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from glob import glob\n",
    "from geopy.distance import vincenty\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Trip Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Loading Trip Data...')\n",
    "\n",
    "try:\n",
    "    file_path_slug = '../../datasets/bayareabikeshare/*_trip_data.csv'\n",
    "    file_list = glob(file_path_slug)\n",
    "\n",
    "    trip_import = pd.DataFrame()\n",
    "    \n",
    "    counter = 1\n",
    "    chunks = []\n",
    "    \n",
    "    for file in file_list:\n",
    "        for chunk in pd.read_csv(file, chunksize=10000, iterator=True):\n",
    "            chunk = chunk.set_index('Trip ID')\n",
    "            chunk.columns = ['Duration', 'Start Date', 'Start Station', 'Start Terminal', 'End Date', \n",
    "                             'End Station', 'End Terminal', 'Bike #', 'Subscriber Type', 'Zip Code']\n",
    "            chunks.append(chunk)\n",
    "        print('\\tFinished file! (%d of %d)' % (counter, len(file_list)))\n",
    "        counter += 1\n",
    "\n",
    "    trip_import = pd.concat(chunks)\n",
    "    print('Data Loaded Successfully!')\n",
    "\n",
    "except:\n",
    "    print('oops... something went wrong importing the data :(')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trip_data = trip_import.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Weather Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Loading Weather Data...')\n",
    "\n",
    "try:\n",
    "    file_path_slug = '../../datasets/bayareabikeshare/*_weather_data.csv'\n",
    "    file_list = glob(file_path_slug)\n",
    "\n",
    "    weather_import = pd.DataFrame()\n",
    "\n",
    "    counter = 1\n",
    "    chunks = []\n",
    "\n",
    "    for file in file_list:\n",
    "        for chunk in pd.read_csv(file, chunksize=10000, iterator=True):\n",
    "            chunk.columns = ['Date', 'Max_Temperature_F', 'Mean_Temperature_F', 'Min_TemperatureF', 'Max_Dew_Point_F', \n",
    "                             'MeanDew_Point_F', 'Min_Dewpoint_F', 'Max_Humidity', 'Mean_Humidity', 'Min_Humidity', \n",
    "                             'Max_Sea_Level_Pressure_In', 'Mean_Sea_Level_Pressure_In', 'Min_Sea_Level_Pressure_In', \n",
    "                             'Max_Visibility_Miles', 'Mean_Visibility_Miles', 'Min_Visibility_Miles', \n",
    "                             'Max_Wind_Speed_MPH', 'Mean_Wind_Speed_MPH', 'Max_Gust_Speed_MPH', 'Precipitation_In', \n",
    "                             'Cloud_Cover', 'Events', 'Wind_Dir_Degrees', 'zip']\n",
    "            chunks.append(chunk)\n",
    "        print('\\tfinished file! (%d of %d)'% (counter, len(file_list)))\n",
    "        counter += 1\n",
    "\n",
    "    weather_import = pd.concat(chunks)\n",
    "    print('Data Loaded Successfully!')\n",
    "except:\n",
    "    print('oops... something went wrong loading the data :()')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weather_data = weather_import.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Station Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Loading Station Data...')\n",
    "\n",
    "try:\n",
    "    file_path_slug = '../../datasets/bayareabikeshare/*_station_data.csv'\n",
    "    file_list = glob(file_path_slug)\n",
    "\n",
    "    station_import = pd.DataFrame()\n",
    "\n",
    "    counter = 1\n",
    "    chunks = []\n",
    "\n",
    "    for file in file_list:\n",
    "        for chunk in pd.read_csv(file, chunksize=10000, iterator=True):\n",
    "            chunk.columns = ['station_id', 'name', 'lat', 'long', 'dockcount', 'landmark', 'installation']            \n",
    "            chunks.append(chunk)\n",
    "        print('\\tFinished file! (%d of %d)' % (counter, len(file_list)))\n",
    "        counter += 1\n",
    "\n",
    "    station_import = pd.concat(chunks)\n",
    "    print('Data Loaded Successfully!')\n",
    "except:\n",
    "    print('oops... something went wrong importing the data :(')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "station_data = station_import.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trip Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# our data set show duration in seconds, here are some handy conversions\n",
    "second = 1\n",
    "minute = second * 60\n",
    "hour = minute * 60\n",
    "\n",
    "# zipcodes are all over the place, only keep corrected 5 digit zipcodes, and replace all others with NaNs\n",
    "def clean_zipcode(item):\n",
    "    if len(item) != 5:\n",
    "        # split on '-'\n",
    "        try:\n",
    "            result = item.split('-')[0]\n",
    "        except:\n",
    "            result = item\n",
    "        # split on '.'\n",
    "        try:\n",
    "            result = item.split('.')[0]\n",
    "        except:\n",
    "            result = item\n",
    "        # if len of item is less than 5, return 'NaN'\n",
    "        if len(result) < 5:\n",
    "            result = 'NaN'\n",
    "        else:\n",
    "            # if len result is greater than 5, take at most, first 5 digits\n",
    "            result = result[:5]\n",
    "    else:\n",
    "        result = item\n",
    "    # make sure result is all digits\n",
    "    if result.isdigit():\n",
    "        return result\n",
    "    else:\n",
    "        return 'NaN'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Trip Data Cleanup Started...')\n",
    "\n",
    "# cleanup column names\n",
    "print('\\tcleaning column names')\n",
    "new_cols = []\n",
    "for col in trip_data.columns:\n",
    "    new_cols.append(col.replace(' ', '_').lower())\n",
    "trip_data.columns = new_cols\n",
    "\n",
    "# extract columns we want to keep\n",
    "print('\\tsubsetting to useful columns')\n",
    "important_cols = ['duration', 'start_date', 'start_terminal', 'end_date', 'end_terminal', 'bike_#', 'subscriber_type', 'zip_code']\n",
    "trip_data = trip_data[important_cols]\n",
    "\n",
    "# create duration minutes column\n",
    "print('\\tcreating a duration_minutes column')\n",
    "trip_data['duration_minutes'] = trip_data['duration'] / 60.0\n",
    "\n",
    "# convert end and start dates to datetime objects\n",
    "print('\\tconverting end and start dates to datetime objects')\n",
    "trip_data['start_date'] = pd.to_datetime(trip_data['start_date'], format=\"%m/%d/%Y %H:%M\")\n",
    "trip_data['end_date']   = pd.to_datetime(trip_data['end_date'],   format=\"%m/%d/%Y %H:%M\")\n",
    "\n",
    "# create a start and end hour trip column\n",
    "print('\\tcreating trip_date and trip_dow columns')\n",
    "trip_data['trip_date']  = trip_data['start_date'].dt.date\n",
    "trip_data['trip_dow']  = trip_data['start_date'].dt.weekday\n",
    "trip_data['trip_day']  = trip_data['start_date'].dt.weekday_name\n",
    "\n",
    "print('\\tcreating start_hour and end_hour columns')\n",
    "trip_data['start_hour'] = trip_data['start_date'].dt.hour\n",
    "trip_data['end_hour']   = trip_data['end_date'].dt.hour\n",
    "\n",
    "# convert and clean zipcodes\n",
    "print('\\tcleaning zipcodes')\n",
    "trip_data['zip_code'] = trip_data['zip_code'].astype(str)\n",
    "trip_data.zip_code = trip_data.zip_code.apply(clean_zipcode)\n",
    "trip_data['zip_code'] = pd.to_numeric(trip_data['zip_code'], errors='coerce')\n",
    "\n",
    "# clean up data types\n",
    "print('cleaning up data types')\n",
    "\n",
    "trip_data['duration']         = trip_data['duration'].astype('float')\n",
    "trip_data['start_terminal']   = trip_data['start_terminal'].astype('category')\n",
    "trip_data['end_terminal']     = trip_data['end_terminal'].astype('category')\n",
    "trip_data['bike_#']           = trip_data['bike_#'].astype('int')\n",
    "trip_data['subscriber_type']  = trip_data['subscriber_type'].astype('category')\n",
    "trip_data['zip_code']         = trip_data['zip_code'].astype('str')\n",
    "trip_data['duration_minutes'] = trip_data['duration_minutes'].astype('float')\n",
    "trip_data['trip_dow']         = trip_data['trip_dow'].astype('category')\n",
    "trip_data['trip_day']         = trip_data['trip_day'].astype('category')\n",
    "\n",
    "# prune data to exclude trips longer than 60 minutes\n",
    "print('pruning data to trips no more than 60 minutes long...')\n",
    "trip_data = trip_data[trip_data['duration_minutes'] <= 60]\n",
    "\n",
    "# Cleanup\n",
    "trip_data.sort_index(inplace=True)\n",
    "print('\\tpruned data set \\'trip_data\\' consists of %i entries' % len(trip_data.index))\n",
    "\n",
    "print('Trip Data Cleanup complete')\n",
    "trip_clean = trip_data.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weather Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Weather Data Cleanup Started...')\n",
    "\n",
    "# cleanup column names\n",
    "print('\\tcleaning column names')\n",
    "new_cols = []\n",
    "for col in weather_data.columns:\n",
    "    new_cols.append(col.replace(' ', '_').lower())\n",
    "weather_data.columns = new_cols\n",
    "\n",
    "# convert end and start dates to datetime objects\n",
    "print('\\tconverting dates to datetime objects')\n",
    "weather_data['date'] = pd.to_datetime(weather_data['date'], format=\"%m/%d/%Y\")\n",
    "\n",
    "# extract columns we want to keep\n",
    "print('\\tsubsetting to useful columns')\n",
    "important_cols = ['date', 'max_temperature_f', 'mean_temperature_f', 'min_temperaturef',\n",
    "                  'max_wind_speed_mph', 'mean_wind_speed_mph', 'max_gust_speed_mph',\n",
    "                  'precipitation_in', 'cloud_cover', 'events', 'zip']\n",
    "weather_data = weather_data[important_cols]\n",
    "\n",
    "# correct min_temperaturef column name to min_temperature_f\n",
    "weather_data.rename(columns={'min_temperaturef': 'min_temperature_f'}, inplace=True)\n",
    "\n",
    "# cleanup and set date as index\n",
    "weather_data.set_index('date', inplace=True)\n",
    "weather_data.sort_index(inplace=True)\n",
    "\n",
    "# cleanup precipitation data to be all float values\n",
    "weather_data['precipitation_in'] = pd.to_numeric(weather_data['precipitation_in'], errors='coerce')\n",
    "\n",
    "# we only want San Francisco Weather information, zipcode 94107\n",
    "weather_data = weather_data[weather_data.zip == 94107]\n",
    "\n",
    "print('Weather Data Cleanup complete')\n",
    "weather_clean = weather_data.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Station Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def label_zip(row):\n",
    "    if row['landmark'] == 'San Francisco':\n",
    "       return '94107'\n",
    "    if row['landmark'] == 'Redwood City':\n",
    "        return '94063'\n",
    "    if row['landmark'] == 'Palo Alto':\n",
    "        return '94301'\n",
    "    if row['landmark'] == 'Mountain View':\n",
    "        return '94041'\n",
    "    if row['landmark'] == 'San Jose':\n",
    "        return '95113'\n",
    "    return '99999'\n",
    "\n",
    "def make_lat_long(row):\n",
    "    lat = row['lat']\n",
    "    long = row['long']\n",
    "    return (lat, long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_data = station_import.copy()\n",
    "\n",
    "# remove dulplicates\n",
    "print('remove dulplicates')\n",
    "station_data.drop_duplicates(keep='first', inplace=True)\n",
    "station_data.dropna(how='all', inplace=True)\n",
    "\n",
    "# set datatype for each column\n",
    "print('set datatype for each column')\n",
    "station_data['station_id']   = station_data['station_id'].astype('int')\n",
    "station_data['name']         = station_data['name'].astype('str')\n",
    "station_data['lat']          = station_data['lat'].astype('float')\n",
    "station_data['long']         = station_data['long'].astype('float')\n",
    "station_data['landmark']     = station_data['landmark'].astype('category')\n",
    "\n",
    "# add a zipcode column for later comparison with weather data\n",
    "station_data['zip_code'] = station_data.apply(lambda row: label_zip (row),axis=1)\n",
    "# station_data['zip_code'] = station_data['landmark'].astype('str')\n",
    "\n",
    "# create lat,lon tuple column\n",
    "station_data['lat_long'] = station_data.apply(lambda row: make_lat_long (row),axis=1)\n",
    "\n",
    "# reindex to remove some extra duplicate\n",
    "print('correcting index')\n",
    "station_data.reset_index(inplace=True)\n",
    "station_data.drop_duplicates(['station_id', 'installation'], keep='first', inplace=True)\n",
    "station_data.set_index('station_id', inplace=True)\n",
    "station_data.sort_index(inplace=True)\n",
    "del station_data['index']\n",
    "\n",
    "station_clean = station_data.copy()\n",
    "print('Cleaning complete!')\n",
    "station_clean.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appending Distance Data to Trips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def route_distance(row):\n",
    "    \n",
    "    # round trips are defaulting to zero km\n",
    "    if row['start_terminal'] == row['end_terminal']:\n",
    "        dist = 0.0\n",
    "    else:\n",
    "        # lookup start_station id coords\n",
    "        start_gps = station_clean.loc[row['start_terminal']]['lat_long']\n",
    "        end_gps = station_clean.loc[row['end_terminal']]['lat_long']\n",
    "\n",
    "        if isinstance(start_gps, pd.core.series.Series):\n",
    "            start_gps = start_gps.iloc[-1]\n",
    "        if isinstance(end_gps, pd.core.series.Series):\n",
    "            end_gps = end_gps.iloc[-1]\n",
    "        # sloppy lookup, uses most recent station coordinates\n",
    "        # does not account for stations that are relocated over time correctly\n",
    "        try:\n",
    "            dist = str(vincenty(start_gps, end_gps))\n",
    "            dist = float(dist.split(' ')[0])\n",
    "        except:\n",
    "            dist = 'NaN'  \n",
    "    return dist\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# trip_clean['distance_km'] = trip_clean.apply(lambda row: route_distance (row),axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting up Rainy and Dry Days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# split up rainy days and dry days\n",
    "rainy_days = weather_clean[ weather_clean['precipitation_in'] > 0.0].reset_index()\n",
    "dry_days =   weather_clean[-weather_clean['precipitation_in'] > 0.0].reset_index()\n",
    "\n",
    "# All trips\n",
    "rainy_trips = trip_clean[ trip_clean['start_date'].dt.date.isin(rainy_days['date'].dt.date)]\n",
    "dry_trips   = trip_clean[-trip_clean['start_date'].dt.date.isin(rainy_days['date'].dt.date)]\n",
    "\n",
    "# Customer Trips\n",
    "customer_rainy_trips = rainy_trips[rainy_trips.subscriber_type == 'Customer']\n",
    "customer_dry_trips = dry_trips[dry_trips.subscriber_type == 'Customer']\n",
    "\n",
    "# Subscriber Trips\n",
    "subscriber_rainy_trips = rainy_trips[rainy_trips.subscriber_type == 'Subscriber']\n",
    "subscriber_dry_trips = dry_trips[dry_trips.subscriber_type == 'Subscriber']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting up Hot and Cold Days\n",
    "\n",
    "- Hot days are days with a mean temperature over 70°F\n",
    "- Cold days are days with a mean temperature below 50°F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# split up rainy days and dry days\n",
    "hot_days = weather_clean[weather_clean['mean_temperature_f'] > 75.0].reset_index()\n",
    "cold_days = weather_clean[weather_clean['mean_temperature_f'] < 45.0].reset_index()\n",
    "\n",
    "# normal days are days not in either hot or cold days\n",
    "norm_days = weather_clean[weather_clean['mean_temperature_f'] <= 75.0]\n",
    "norm_days = norm_days[norm_days['mean_temperature_f'] >= 45.0].reset_index()\n",
    "\n",
    "\n",
    "# All trips\n",
    "hot_trips  = trip_clean[trip_clean['start_date'].dt.date.isin(hot_days['date'].dt.date)]\n",
    "cold_trips = trip_clean[trip_clean['start_date'].dt.date.isin(cold_days['date'].dt.date)]\n",
    "norm_trips = trip_clean[trip_clean['start_date'].dt.date.isin(norm_days['date'].dt.date)]\n",
    "\n",
    "\n",
    "# Customer Trips\n",
    "customer_hot_trips  = hot_trips[hot_trips.subscriber_type == 'Customer']\n",
    "customer_cold_trips = cold_trips[cold_trips.subscriber_type == 'Customer']\n",
    "customer_norm_trips = norm_trips[norm_trips.subscriber_type == 'Customer']\n",
    "\n",
    "# Subscriber Trips\n",
    "subscriber_hot_trips  = hot_trips[hot_trips.subscriber_type == 'Subscriber']\n",
    "subscriber_cold_trips = cold_trips[cold_trips.subscriber_type == 'Subscriber']\n",
    "subscriber_norm_trips = norm_trips[norm_trips.subscriber_type == 'Subscriber']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(hot_trips))\n",
    "print(len(cold_trips))\n",
    "print(len(norm_trips))\n",
    "print('------')\n",
    "print(len(norm_trips) + len(hot_trips) + len(cold_trips))\n",
    "print(len(trip_clean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_stats(data1, data2):\n",
    "\n",
    "    # means\n",
    "    data1_mean = data1.mean()\n",
    "    data2_mean = data2.mean()\n",
    "    diff_mean = data1_mean - data2_mean\n",
    "    print('Diff of means:\\t\\t', diff_mean)\n",
    "\n",
    "    # calculate t statistic and p value with scipy\n",
    "    t, p = stats.ttest_ind(data1, data2)\n",
    "    print('T Test')\n",
    "    print('\\tt statistic:\\t\\t', t)\n",
    "    print('\\tp value:\\t\\t', p)\n",
    "    print('')\n",
    "    u, p2 = stats.mannwhitneyu(data1, data2)\n",
    "    print('MannWhitneyU Test')\n",
    "    print('\\tu statistic:\\t\\t', u)\n",
    "    print('\\tp value:\\t\\t', p2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Does Rain Affect Trips Duration of Customers or of Subscribers?\n",
    "\n",
    "> A <b>Two Sample T Test</b> is appropriate for this problem as we are trying to see a difference between two sample means\n",
    "- Mean ride duration on rainy days vs mean ride duration on dry days\n",
    ">\n",
    "> ##### Customer Trips\n",
    "- $H1C$o : Customer Mean Number of trips on Rainy Days = Customer Mean Number of trips on Dry Days\n",
    "- $H1C$a : Customer Mean Number of trips on Rainy Days ≠ Customer Mean Number of trips on Dry Days\n",
    ">\n",
    "> ##### Subscriber Trips\n",
    "- $H2S$o : Subscriber Mean Number of trips on Rainy Days = Subscriber Mean Number of trips on Dry Days\n",
    "- $H2S$a : Subscriber Mean Number of trips on Rainy Days ≠ Subscriber Mean Number of trips on Dry Days"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Results\n",
    "\n",
    "> #### Customer Trips\n",
    "> Mean trip durations on rainy days are equal mean trip durations on dry days\n",
    "- T Statistic <b>-1.4050</b> \n",
    "- P Value <b>0.1667</b> which is above the 0.05 threshhold thus we <b>can not reject</b> the $HC$o\n",
    "\n",
    "\n",
    "> #### Subscriber Trips\n",
    "> Mean trip durations on rainy days are not equal to mean trip durations on dry days\n",
    "- T Statistic <b>0.1287</b> \n",
    "- P Value <b>0.8981</b> which is above the 0.05 threshhold thus we <b>can not reject</b> the $HS$o\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Customer Trips Only\n",
    "\n",
    "customer_rainy_data = customer_rainy_trips.groupby('start_hour')['duration'].count() / len(rainy_trips)\n",
    "customer_dry_data = customer_dry_trips.groupby('start_hour')['duration'].count() / len(dry_trips)\n",
    "\n",
    "# Subscriber Trips Only\n",
    "subscriber_rainy_data = subscriber_rainy_trips.groupby('start_hour')['duration'].count() / len(rainy_trips)\n",
    "subscriber_dry_data = subscriber_dry_trips.groupby('start_hour')['duration'].count() / len(dry_trips)\n",
    "\n",
    "print('-' * 40)\n",
    "print('Customer Trips')\n",
    "calculate_stats(customer_rainy_data, customer_dry_data)\n",
    "print()\n",
    "print('-' * 40)\n",
    "print('Subscriber Trips')\n",
    "calculate_stats(subscriber_rainy_data, subscriber_dry_data)\n",
    "print()\n",
    "print('-' * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_hot_data\n",
    "customer_cold_data\n",
    "# customer_rainy_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Does Temperature Affect the average number of trips of Customers or of Subscribers?\n",
    "\n",
    "> A <b>Two Sample T Test</b> is appropriate for this problem as we are trying to see a difference between two sample means\n",
    "- Mean ride duration on rainy days vs mean ride duration on dry days\n",
    ">\n",
    ">\n",
    "> ##### Customer Trips - Hot Days\n",
    "- $H1C$o : Customer Mean Number of trips on Hot Days = Customer Mean Number of trips on Normal Days\n",
    "- $H1C$a : Customer Mean Number of trips on Hot Days ≠ Customer Mean Number of trips on Normal Days\n",
    ">\n",
    "> ##### Subscriber Trips - Hot Days\n",
    "- $H1S$o : Subscriber Mean Number of trips on Hot Days = Subscriber Mean Number of trips on Normal Days\n",
    "- $H1S$a : Subscriber Mean Number of trips on Hot Days ≠ Subscriber Mean Number of trips on Normal Days\n",
    "\n",
    "\n",
    "> ##### Customer Trips - Cold Days\n",
    "- $H2C$o : Customer Mean Number of trips on Cold Days = Customer Mean Number of trips on Normal Days\n",
    "- $H2C$a : Customer Mean Number of trips on Cold Days ≠ Customer Mean Number of trips on Normal Days\n",
    ">\n",
    "> ##### Subscriber Trips - Cold Days\n",
    "- $H2S$o : Subscriber Mean Number of trips on Cold Days = Subscriber Mean Number of trips on Normal Days\n",
    "- $H2S$a : Subscriber Mean Number of trips on Cold Days ≠ Subscriber Mean Number of trips on Normal Days"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Results - Hot Days\n",
    "\n",
    "> #### Customer Trips\n",
    "> Mean trip durations on rainy days are equal mean trip durations on dry days\n",
    "- T Statistic <b>-0.2014</b> \n",
    "- P Value <b>0.8413</b> which is above the 0.05 threshhold thus we <b>can not reject</b> the $H1C$o\n",
    "\n",
    "> #### Subscriber Trips\n",
    "> Mean trip durations on rainy days are not equal to mean trip durations on dry days\n",
    "- T Statistic <b>0.08339</b> \n",
    "- P Value <b>0.9339</b> which is above the 0.05 threshhold thus we <b>can not reject</b> the $H1S$o\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### 2. Results - Cold Days\n",
    "\n",
    "> #### Customer Trips\n",
    "> Mean trip durations on rainy days are equal mean trip durations on dry days\n",
    "- T Statistic <b>0.5714</b> \n",
    "- P Value <b>0.5707</b> which is above the 0.05 threshhold thus we <b>can not reject</b> the $H2C$o\n",
    "\n",
    "> #### Subscriber Trips\n",
    "> Mean trip durations on rainy days are not equal to mean trip durations on dry days\n",
    "- T Statistic <b>-0.0089</b> \n",
    "- P Value <b>0.9929</b> which is above the 0.05 threshhold thus we <b>can not reject</b> the $H2S$o\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n Normal vs Hot Days \\n')\n",
    "\n",
    "# Customer Trips Only\n",
    "customer_hot_data = customer_hot_trips.groupby('start_hour')['duration'].count() / len(hot_trips)\n",
    "customer_norm_data = customer_norm_trips.groupby('start_hour')['duration'].count() / len(norm_trips)\n",
    "\n",
    "# Subscriber Trips Only\n",
    "subscriber_hot_data = subscriber_hot_trips.groupby('start_hour')['duration'].count() / len(hot_trips)\n",
    "subscriber_norm_data = subscriber_norm_trips.groupby('start_hour')['duration'].count() / len(norm_trips)\n",
    "\n",
    "print('-' * 40)\n",
    "print('Customer Trips')\n",
    "calculate_stats(customer_hot_data, customer_norm_data)\n",
    "print()\n",
    "print('-' * 40)\n",
    "print('Subscriber Trips')\n",
    "calculate_stats(subscriber_hot_data, subscriber_norm_data)\n",
    "print()\n",
    "print('-' * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n Normal vs Cold Days \\n')\n",
    "\n",
    "# Customer Trips Only\n",
    "customer_cold_data = customer_cold_trips.groupby('start_hour')['duration'].count() / len(cold_trips)\n",
    "customer_norm_data = customer_norm_trips.groupby('start_hour')['duration'].count() / len(norm_trips)\n",
    "\n",
    "# Subscriber Trips Only\n",
    "subscriber_cold_data = subscriber_cold_trips.groupby('start_hour')['duration'].count() / len(cold_trips)\n",
    "subscriber_norm_data = subscriber_norm_trips.groupby('start_hour')['duration'].count() / len(norm_trips)\n",
    "\n",
    "print('-' * 40)\n",
    "print('Customer Trips')\n",
    "calculate_stats(customer_cold_data, customer_norm_data)\n",
    "print()\n",
    "print('-' * 40)\n",
    "print('Subscriber Trips')\n",
    "calculate_stats(subscriber_cold_data, subscriber_norm_data)\n",
    "print()\n",
    "print('-' * 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Compare morning and evening commute hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def commute_timer(row, start_time):\n",
    "    orig = row.start_date.to_pydatetime()\n",
    "    orig_time = orig.time()\n",
    "    \n",
    "    a = datetime.timedelta(hours=orig_time.hour, minutes=orig_time.minute, seconds=orig_time.second)\n",
    "    b = datetime.timedelta(hours=start_time.hour, minutes=start_time.minute, seconds=start_time.second)\n",
    "\n",
    "    result = a - b\n",
    "    \n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subscriber_trips = trip_clean[trip_clean.subscriber_type == 'Subscriber']\n",
    "\n",
    "\n",
    "\n",
    "# prune only morning commute hours from subscribers [07:00 - 11:00]\n",
    "am_commute_start = datetime.datetime.strptime('07:00', '%H:%M').time()\n",
    "am_commute_end = datetime.datetime.strptime('11:00', '%H:%M').time()\n",
    "morning_commutes = subscriber_trips[subscriber_trips.start_date.dt.time >= am_commute_start]\n",
    "morning_commutes = morning_commutes[morning_commutes.start_date.dt.time < am_commute_end]\n",
    "\n",
    "# prune only evening commute hours from subscribers [16:00 - 20:00]\n",
    "pm_commute_start = datetime.datetime.strptime('16:00', '%H:%M').time()\n",
    "pm_commute_end = datetime.datetime.strptime('20:00', '%H:%M').time()\n",
    "evening_commutes = subscriber_trips[subscriber_trips.start_date.dt.time >= pm_commute_start]\n",
    "evening_commutes = evening_commutes[evening_commutes.start_date.dt.time < pm_commute_end]\n",
    "\n",
    "# morning_commutes['time_adjust'] = morning_commutes.start_date.dt.time - am_commute_start\n",
    "morning_commutes['time_adj'] = morning_commutes.apply(lambda row: commute_timer(row, am_commute_start),axis=1)\n",
    "evening_commutes['time_adj'] = evening_commutes.apply(lambda row: commute_timer(row, pm_commute_start),axis=1)\n",
    "\n",
    "# fix time_adj type\n",
    "morning_commutes.time_adj = morning_commutes.time_adj.astype('timedelta64[m]')\n",
    "evening_commutes.time_adj = evening_commutes.time_adj.astype('timedelta64[m]')\n",
    "\n",
    "print('morning_commutes:\\t', len(morning_commutes))\n",
    "print('evening_commutes:\\t', len(evening_commutes))\n",
    "\n",
    "# plot the data\n",
    "plt.subplots(figsize=(12,6))\n",
    "\n",
    "ax = sns.distplot(morning_commutes.time_adj, color='b', label='morning')\n",
    "sns.distplot(evening_commutes.time_adj, color='y', label='evening', ax=ax)\n",
    "\n",
    "ax.set(xlabel='start hour')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# calculate some statistics\n",
    "am_commuters = morning_commutes.groupby('time_adj')['start_terminal'].count()\n",
    "pm_commuters = evening_commutes.groupby('time_adj')['start_terminal'].count()\n",
    "\n",
    "print('-' * 40)\n",
    "print('Commuter Trips')\n",
    "calculate_stats(am_commuters, pm_commuters)\n",
    "print()\n",
    "print('-' * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "junk_sub = pd.DataFrame()\n",
    "junk_sub['cold'] = subscriber_cold_data\n",
    "junk_sub['hot'] = subscriber_hot_data\n",
    "junk_sub['norm'] = subscriber_norm_data\n",
    "\n",
    "sns.jointplot(x='hot', y='norm', data=junk_sub, kind='reg')\n",
    "plt.show()\n",
    "sns.jointplot(x='cold', y='norm', data=junk_sub, kind='reg')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "junk_cust = pd.DataFrame()\n",
    "junk_cust['cold'] = customer_cold_data\n",
    "junk_cust['hot'] = customer_hot_data\n",
    "junk_cust['norm'] = customer_norm_data\n",
    "\n",
    "sns.jointplot(x='hot', y='norm', data=junk_cust, kind='reg')\n",
    "plt.show()\n",
    "sns.jointplot(x='cold', y='norm', data=junk_cust, kind='reg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "commute_hours = pd.DataFrame()\n",
    "commute_hours['morning'] = am_commuters\n",
    "commute_hours['evening'] = pm_commuters\n",
    "\n",
    "sns.jointplot(x='morning', y='evening', data=commute_hours, kind='reg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split morning and evening - Subscribers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trip_time_adj(row):\n",
    "    orig = row.start_date.to_pydatetime()\n",
    "    orig_time = orig.time()\n",
    "    \n",
    "    noon = datetime.datetime.strptime('12:00', '%H:%M').time()\n",
    "    midnight = datetime.datetime.strptime('00:00', '%H:%M').time()\n",
    "    \n",
    "    # this is horribly inneficient, but it does work\n",
    "    _orig = datetime.timedelta(hours=orig_time.hour, minutes=orig_time.minute, seconds=orig_time.second)\n",
    "    _noon = datetime.timedelta(hours=noon.hour, minutes=noon.minute, seconds=noon.second)\n",
    "    _midnight = datetime.timedelta(hours=midnight.hour, minutes=midnight.minute, seconds=midnight.second)\n",
    "    \n",
    "    if _orig > _noon:\n",
    "        result = _orig - _noon\n",
    "    else:\n",
    "        result = _midnight + _orig       \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noon = datetime.datetime.strptime('12:00', '%H:%M').time()\n",
    "\n",
    "# split subscriber trips into morning and evening trip times [00:00 - 11:59], [12:00, 23:59]\n",
    "morning_trips = subscriber_trips[subscriber_trips.start_date.dt.time < noon].copy()\n",
    "afternoon_trips = subscriber_trips[subscriber_trips.start_date.dt.time >= noon].copy()\n",
    "\n",
    "# create adjusted time for comparison, reduced to minutes after midnight and minutes after noon\n",
    "morning_trips['time_adj'] = morning_trips.apply(lambda row: trip_time_adj(row),axis=1)\n",
    "afternoon_trips['time_adj'] = afternoon_trips.apply(lambda row: trip_time_adj(row),axis=1)\n",
    "\n",
    "# fix time_adj type\n",
    "morning_trips.time_adj = morning_trips.time_adj.astype('timedelta64[m]')\n",
    "afternoon_trips.time_adj = afternoon_trips.time_adj.astype('timedelta64[m]')\n",
    "\n",
    "print('morning_trips:\\t\\t', len(morning_trips))\n",
    "print('afternoon_trips:\\t', len(afternoon_trips))\n",
    "\n",
    "# plot the data\n",
    "plt.subplots(figsize=(12,6))\n",
    "\n",
    "sns.distplot(morning_trips.time_adj, color='b', label='morning')\n",
    "sns.distplot(afternoon_trips.time_adj, color='y', label='evening')\n",
    "\n",
    "ax.set(xlabel='start hour')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# calculate some statistics!\n",
    "am_trips = morning_trips.groupby('time_adj')['start_terminal'].count()\n",
    "pm_trips = afternoon_trips.groupby('time_adj')['start_terminal'].count()\n",
    "\n",
    "print('-' * 40)\n",
    "print('Commuter Trips')\n",
    "calculate_stats(am_trips, pm_trips)\n",
    "print()\n",
    "print('-' * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots(figsize=(12,6))\n",
    "sns.distplot(trip_clean[trip_clean.subscriber_type == 'Customer'].start_date.dt.hour, color='r', label='Customers')\n",
    "ax.set(xlabel='start hour')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split morning and evening - Customers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_trips = trip_clean[trip_clean.subscriber_type == 'Customer']\n",
    "\n",
    "noon = datetime.datetime.strptime('12:00', '%H:%M').time()\n",
    "\n",
    "# prune only morning commute hours from customers [07:00 - 11:00]\n",
    "am_trip_start = datetime.datetime.strptime('06:00', '%H:%M').time()\n",
    "am_trip_end   = datetime.datetime.strptime('12:00', '%H:%M').time()\n",
    "\n",
    "morning_trips = customer_trips[customer_trips.start_date.dt.time >= am_commute_start].copy()\n",
    "morning_trips = morning_trips[morning_trips.start_date.dt.time < am_commute_end].copy()\n",
    "\n",
    "# prune only evening commute hours from customers [15:00 - 20:00]\n",
    "pm_trip_start = datetime.datetime.strptime('12:00', '%H:%M').time()\n",
    "pm_trip_end   = datetime.datetime.strptime('18:00', '%H:%M').time()\n",
    "\n",
    "evening_trips = customer_trips[customer_trips.start_date.dt.time >= pm_commute_start].copy()\n",
    "evening_trips = evening_trips[evening_trips.start_date.dt.time < pm_commute_end].copy()\n",
    "\n",
    "# create adjusted time for comparison, reduced to minutes after midnight and minutes after noon\n",
    "morning_trips['time_adj'] = morning_trips.apply(lambda row: commute_timer(row, am_trip_start),axis=1)\n",
    "evening_trips['time_adj'] = evening_trips.apply(lambda row: commute_timer(row, pm_trip_start),axis=1)\n",
    "\n",
    "# fix time_adj type\n",
    "morning_trips.time_adj = morning_trips.time_adj.astype('timedelta64[m]')\n",
    "evening_trips.time_adj = evening_trips.time_adj.astype('timedelta64[m]')\n",
    "\n",
    "print('morning_trips:\\t', len(morning_trips))\n",
    "print('evening_trips:\\t', len(evening_trips))\n",
    "\n",
    "# plot the data\n",
    "plt.subplots(figsize=(12,6))\n",
    "\n",
    "sns.distplot(morning_trips.time_adj, color='b', label='morning')\n",
    "sns.distplot(evening_trips.time_adj, color='y', label='evening')\n",
    "\n",
    "ax.set(xlabel='start hour')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# calculate some statistics!\n",
    "am_trips = morning_trips.groupby('time_adj')['start_terminal'].count()\n",
    "pm_trips = evening_trips.groupby('time_adj')['start_terminal'].count()\n",
    "\n",
    "print('-' * 40)\n",
    "print('Commuter Trips')\n",
    "calculate_stats(am_trips, pm_trips)\n",
    "print()\n",
    "print('-' * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
