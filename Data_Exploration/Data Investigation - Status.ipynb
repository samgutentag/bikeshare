{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Investigation - Status Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "import datetime\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Loading Status Data...')\n",
    "\n",
    "status_01 = pd.DataFrame()\n",
    "status_02 = pd.DataFrame()\n",
    "status_03 = pd.DataFrame()\n",
    "status_04 = pd.DataFrame()\n",
    "\n",
    "try:\n",
    "    file_path_slug = '../../../datasets/bayareabikeshare/*_status_data.csv'\n",
    "\n",
    "    # glob all files\n",
    "    file_list = glob(file_path_slug)\n",
    "\n",
    "    status_import = pd.DataFrame()\n",
    "\n",
    "    counter = 1\n",
    "    \n",
    "\n",
    "    # load data from each file\n",
    "    for file in file_list:\n",
    "        chunks = []\n",
    "        # import file in chunks\n",
    "        for chunk in pd.read_csv(file, chunksize=10000, iterator=True):\n",
    "\n",
    "            # append chunk to chunks list\n",
    "            chunks.append(chunk)\n",
    "\n",
    "        if counter == 1:\n",
    "            status_01 = pd.concat(chunks)\n",
    "        elif counter == 2:\n",
    "            status_02 = pd.concat(chunks)\n",
    "        elif counter == 3:\n",
    "            status_03 = pd.concat(chunks)\n",
    "        elif counter == 4:\n",
    "            status_04 = pd.concat(chunks)\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "        \n",
    "        print('\\tFinished file! (%d of %d)' % (counter, len(file_list)))\n",
    "        counter += 1\n",
    "\n",
    "\n",
    "\n",
    "    print('Data Loaded Successfully!')\n",
    "\n",
    "except:\n",
    "    print('oops... something went wrong importing the data :(')\n",
    "    \n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# status_data = status_import.copy()\n",
    "# status_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# status_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean And Resample Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert time to datetime\n",
    "status_01_copy = status_01.copy()\n",
    "status_01_copy['time']   = pd.to_datetime(status_01_copy['time'],   format=\"%Y/%m/%d %H:%M:%S\")\n",
    "\n",
    "\n",
    "status_02_copy = status_02.copy()\n",
    "status_02_copy['time']   = pd.to_datetime(status_02_copy['time'],   format=\"%Y/%m/%d %H:%M:%S\")\n",
    "\n",
    "\n",
    "status_03_copy = status_03.copy()\n",
    "status_03_copy['time']   = pd.to_datetime(status_03_copy['time'],   format=\"%m/%d/%Y %H:%M:%S\")\n",
    "\n",
    "\n",
    "status_04_copy = status_04.copy()\n",
    "status_04_copy['time']   = pd.to_datetime(status_04_copy['time'],   format=\"%Y/%m/%d %H:%M:%S\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "status_02_copy.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "status_time_clean = pd.concat([status_01_copy, status_02_copy, status_03_copy, status_04_copy])\n",
    "status_time_clean.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# append total_docks column\n",
    "status_time_clean['total_docks'] = status_time_clean['bikes_available'] + status_time_clean['docks_available']\n",
    "status_time_clean.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "status_time_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set time column as index\n",
    "status_time_clean.set_index('time', inplace=True)\n",
    "\n",
    "status_data = status_time_clean.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> From Analysis of Trip Data, we can see that key commute hours for Subscribers are:\n",
    "-    Morning Commute Hours 07:00-11:00\n",
    "-    Evening Commute Hours 16:00-20:00\n",
    "\n",
    "> From Analysis of Trip Data, we can see that key Stations for Subscribers are:\n",
    "-    Morning Commute Stations \n",
    "    - top_am_commute_start_terms = [50, 54, 55, 61, 67, 69, 70, 73, 74, 77]\n",
    "    - top_am_commute_end_terms   = [51, 55, 60, 61, 63, 65, 69, 70, 74, 77]\n",
    ">\n",
    ">\n",
    "-    Evening Commute Stations \n",
    "    - top_pm_commute_start_terms = [55, 60, 61, 64, 65, 67, 69, 70, 74, 77]\n",
    "    - top_pm_commute_end_terms   = [39, 50, 55, 60, 61, 65, 69, 70, 74, 77]\n",
    ">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prune only morning commute hours from subscribers [07:00 - 11:00]\n",
    "am_commute_start = datetime.datetime.strptime('07:00', '%H:%M').time()\n",
    "am_commute_end = datetime.datetime.strptime('11:00', '%H:%M').time()\n",
    "morning_commute_status = status_data.between_time(start_time=am_commute_start,\n",
    "                                                     end_time=am_commute_end,\n",
    "                                                     include_start=True,\n",
    "                                                     include_end=True)\n",
    "\n",
    "morning_commute_status.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prune only evening commute hours from subscribers [16:00 - 20:00]\n",
    "pm_commute_start = datetime.datetime.strptime('16:00', '%H:%M').time()\n",
    "pm_commute_end = datetime.datetime.strptime('20:00', '%H:%M').time()\n",
    "evening_commute_status = status_data.between_time(start_time=pm_commute_start,\n",
    "                                                     end_time=pm_commute_end,\n",
    "                                                     include_start=True,\n",
    "                                                     include_end=True)\n",
    "\n",
    "evening_commute_status.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# prune only important stations for each commute period\n",
    "top_am_commute_start_terms = [50, 54, 55, 61, 67, 69, 70, 73, 74, 77]\n",
    "top_am_commute_end_terms = [51, 55, 60, 61, 63, 65, 69, 70, 74, 77]\n",
    "top_pm_commute_start_terms = [55, 60, 61, 64, 65, 67, 69, 70, 74, 77]\n",
    "top_pm_commute_end_terms = [39, 50, 55, 60, 61, 65, 69, 70, 74, 77]\n",
    "\n",
    "\n",
    "morning_commute_status_start = morning_commute_status[morning_commute_status.station_id.isin(top_am_commute_start_terms)].copy()\n",
    "morning_commute_status_end   = morning_commute_status[morning_commute_status.station_id.isin(top_am_commute_end_terms)].copy()\n",
    "evening_commute_status_start = evening_commute_status[evening_commute_status.station_id.isin(top_pm_commute_start_terms)].copy()\n",
    "evening_commute_status_end   = evening_commute_status[evening_commute_status.station_id.isin(top_pm_commute_end_terms)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "morning_commute_status_start.groupby(['station_id', morning_commute_status_start.index.hour])['docks_available'].plot(figsize=(12,6))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "morning_commute_status_start.groupby(['station_id', morning_commute_status_start.index.hour, morning_commute_status_start.index.minute]).mean()['docks_available'].plot(figsize=(12,6))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in pd.unique(morning_commute_status_start.station_id):\n",
    "    data = morning_commute_status_start[morning_commute_status_start.station_id == i]\n",
    "    data.groupby(['station_id', data.index.hour, data.index.minute]).mean()['bikes_available'].plot(figsize=(12,3))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "status_data.info()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in pd.unique(status_data.station_id):\n",
    "    data = status_data[status_data.station_id == i]\n",
    "    data.groupby(['station_id', data.index.hour, data.index.minute]).mean()['bikes_available'].plot(figsize=(12,3))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in pd.unique(status_data.station_id):\n",
    "#     data = status_data[status_data.station_id == i]\n",
    "status_data.groupby([status_data.index.hour, status_data.index.minute]).mean()['bikes_available'].plot(figsize=(12,3))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ax = evening_commute_status.groupby([evening_commute_status.index.hour, evening_commute_status.index.minute]).mean()['bikes_available'].plot(figsize=(12,6))\n",
    "morning_commute_status.groupby([morning_commute_status.index.hour, morning_commute_status.index.minute]).mean()['bikes_available'].plot(ax=ax)\n",
    "plt.legend(['evening', 'morning'],loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ax = evening_commute_status.groupby([evening_commute_status.index.hour, evening_commute_status.index.minute]).sum()['bikes_available'].plot(figsize=(12,6))\n",
    "morning_commute_status.groupby([morning_commute_status.index.hour, morning_commute_status.index.minute]).sum()['bikes_available'].plot(ax=ax)\n",
    "plt.legend(['evening', 'morning'],loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "status_73_data = status_data[status_data.station_id == 73]\n",
    "\n",
    "status_73_data.groupby([status_73_data.index.hour, status_73_data.index.minute]).max()['bikes_available'].plot(figsize=(12,6))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
